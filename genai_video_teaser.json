{
    "00507": {
        "id": "507",
        "prompt": "One cat sleeping under five bright stars",
        "models": {
            "Floor33": {
                "clip_flant5": "0.838",
                "llava": "0.274",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.797",
                "llava": "0.263",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.751",
                "llava": "0.333",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.821",
                "llava": "0.296",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00151": {
        "id": "00151",
        "prompt": "Two red balloons and three white clouds floating in the blue sky.",
        "prompt in Chinese": "\u84dd\u5929\u4e0a\u98d8\u7740\u4e24\u4e2a\u7ea2\u6c14\u7403\u548c\u4e09\u6735\u767d\u4e91\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.908",
                "llava": "0.342",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.911",
                "llava": "0.367",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.930",
                "llava": "0.322",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.409",
                "llava": "0.169",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00352": {
        "id": "352",
        "prompt": "On a busy desk, a lamp sheds light on a cluttered area filled with papers, while the other half remains organized.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.893",
                "llava": "0.461",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.896",
                "llava": "0.485",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.911",
                "llava": "0.493",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.878",
                "llava": "0.401",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00050": {
        "id": "00050",
        "prompt": "Boats laden with fruits floating on a river under a dual sunset.",
        "prompt in Chinese": "\u88c5\u6ee1\u6c34\u679c\u7684\u5c0f\u8239\u5728\u53cc\u65e5\u843d\u4e0b\u7684\u6cb3\u4e0a\u6f02\u6d6e\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.568",
                "llava": "0.120",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.938",
                "llava": "0.533",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.928",
                "llava": "0.573",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.663",
                "llava": "0.202",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00448": {
        "id": "448",
        "prompt": "Two children sitting on the bed, the one on the left making faces, the one on the right not making faces.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.929",
                "llava": "0.479",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.928",
                "llava": "0.506",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.938",
                "llava": "0.565",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.924",
                "llava": "0.530",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00147": {
        "id": "00147",
        "prompt": "Two orange pumpkins behind a group of five spooky Halloween candles.",
        "prompt in Chinese": "\u4e24\u4e2a\u6a59\u8272\u7684\u5357\u74dc\u5728\u4e94\u652f\u8be1\u5f02\u7684\u4e07\u5723\u8282\u8721\u70db\u540e\u9762\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.892",
                "llava": "0.583",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.848",
                "llava": "0.504",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.799",
                "llava": "0.354",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.838",
                "llava": "0.507",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00136": {
        "id": "00136",
        "prompt": "A piece of white paper on the grass, the left side of the paper is filled with writing while the right side is empty.",
        "prompt in Chinese": "\u8349\u5730\u4e0a\u7684\u4e00\u5f20\u767d\u7eb8\uff0c\u5de6\u8fb9\u5199\u6ee1\u4e86\u5b57\uff0c\u53f3\u8fb9\u5374\u7a7a\u7a7a\u5982\u4e5f\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.938",
                "llava": "0.680",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.888",
                "llava": "0.505",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.949",
                "llava": "0.517",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.894",
                "llava": "0.544",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00201": {
        "id": "00201",
        "prompt": "two people; the one on the right has long hair and the one on the left doesn't.",
        "prompt in Chinese": "\u4e24\u4e2a\u4eba\uff1b\u53f3\u8fb9\u7684\u90a3\u4e2a\u6709\u957f\u53d1\uff0c\u5de6\u8fb9\u7684\u90a3\u4e2a\u6ca1\u6709\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.911",
                "llava": "0.548",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.805",
                "llava": "0.522",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.913",
                "llava": "0.605",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.926",
                "llava": "0.497",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00306": {
        "id": "306",
        "prompt": "A fisherman casting a line at sunrise by a tranquil lake.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.797",
                "llava": "0.458",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.872",
                "llava": "0.529",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.961",
                "llava": "0.541",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.836",
                "llava": "0.632",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "3"
            }
        }
    },
    "00480": {
        "id": "480",
        "prompt": "Two dogs playing; one is barking, but the other is not.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.718",
                "llava": "0.414",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.855",
                "llava": "0.465",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.825",
                "llava": "0.463",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.663",
                "llava": "0.420",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00145": {
        "id": "00145",
        "prompt": "Two orange pumpkins and four flying black bats.",
        "prompt in Chinese": "\u4e24\u4e2a\u6a59\u8272\u5357\u74dc\u548c\u56db\u53ea\u98de\u821e\u7684\u9ed1\u8759\u8760\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.807",
                "llava": "0.508",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.560",
                "llava": "0.351",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.881",
                "llava": "0.472",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.799",
                "llava": "0.470",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00290": {
        "id": "00290",
        "prompt": "A man is hugging a box full of flowers on the floor.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.657",
                "llava": "0.432",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.853",
                "llava": "0.441",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.899",
                "llava": "0.567",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.779",
                "llava": "0.552",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00379": {
        "id": "379",
        "prompt": "One person in white jogs with a steady pace, one person in red sprints with all their might.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.806",
                "llava": "0.228",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.448",
                "llava": "0.289",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.752",
                "llava": "0.437",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.387",
                "llava": "0.246",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00124": {
        "id": "00124",
        "prompt": "There are two red flowers on the table and a few yellow flowers under the table.",
        "prompt in Chinese": "\u684c\u5b50\u4e0a\u6709\u4e24\u6735\u7ea2\u82b1\uff0c\u684c\u5b50\u4e0b\u6709\u4e00\u4e9b\u9ec4\u82b1\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.924",
                "llava": "0.464",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.887",
                "llava": "0.487",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.835",
                "llava": "0.442",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.116",
                "llava": "0.179",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00225": {
        "id": "00225",
        "prompt": "A snowy mountain peak with a wooden signpost reading 'Summit Trail' against a clear blue sky.",
        "prompt in Chinese": "\u6e5b\u84dd\u7684\u5929\u7a7a\u4e0b\uff0c\u96ea\u5c71\u5c71\u9876\u7684\u6728\u8d28\u8def\u6807\u4e0a\u5199\u7740'Summit Trail' \u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.930",
                "llava": "0.565",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.954",
                "llava": "0.708",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.939",
                "llava": "0.658",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.867",
                "llava": "0.593",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00506": {
        "id": "506",
        "prompt": "Three apples next to four oranges on a table.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.775",
                "llava": "0.273",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.920",
                "llava": "0.428",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.473",
                "llava": "0.379",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.311",
                "llava": "0.243",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00512": {
        "id": "512",
        "prompt": "Three kites soaring in the sky above two hills.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.679",
                "llava": "0.376",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.935",
                "llava": "0.512",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.964",
                "llava": "0.517",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.223",
                "llava": "0.244",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00177": {
        "id": "00177",
        "prompt": "An injured man sitting on the ground with a man to his right who is helping him.",
        "prompt in Chinese": "\u4e00\u4f4d\u53d7\u4f24\u7684\u7537\u58eb\u5750\u5728\u5730\u4e0a\uff0c\u4ed6\u53f3\u8fb9\u6709\u4e00\u4e2a\u6b63\u5728\u5e2e\u52a9\u4ed6\u7684\u7537\u58eb\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.826",
                "llava": "0.457",
                "human": "1.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.287",
                "llava": "0.346",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.962",
                "llava": "0.511",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.776",
                "llava": "0.399",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00527": {
        "id": "527",
        "prompt": "Five stones by the river.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.787",
                "llava": "0.356",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.804",
                "llava": "0.475",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.753",
                "llava": "0.537",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.645",
                "llava": "0.484",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00179": {
        "id": "00179",
        "prompt": "Two people are running, the person with red legs is running quite slowly and the yellow legged one runs faster.",
        "prompt in Chinese": "\u4e24\u4e2a\u4eba\u5728\u5954\u8dd1\uff0c\u7ea2\u817f\u7684\u4eba\u8dd1\u5f97\u5f88\u6162\uff0c\u9ec4\u817f\u7684\u4eba\u8dd1\u5f97\u66f4\u5feb\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.661",
                "llava": "0.297",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.798",
                "llava": "0.269",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.756",
                "llava": "0.439",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.176",
                "llava": "0.260",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00358": {
        "id": "358",
        "prompt": "In the garden there is a pack of dogs playing, the biggest one is red and the others are white.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.756",
                "llava": "0.550",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.954",
                "llava": "0.647",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.887",
                "llava": "0.649",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.856",
                "llava": "0.484",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00362": {
        "id": "362",
        "prompt": "At the beach, three seashells lie close together: the largest has a spiraled pattern, the medium one is smooth and white, and the smallest has stripes.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.943",
                "llava": "0.709",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.912",
                "llava": "0.545",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.934",
                "llava": "0.683",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.905",
                "llava": "0.665",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00003": {
        "id": "00003",
        "prompt": "A gardener tending to flowers in a greenhouse filled with sunlight.",
        "prompt in Chinese": "\u4e00\u4f4d\u56ed\u827a\u5e08\u5728\u9633\u5149\u5145\u6ee1\u7684\u6e29\u5ba4\u91cc\u7167\u987e\u82b1\u5349\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.979",
                "llava": "0.702",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.954",
                "llava": "0.689",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.909",
                "llava": "0.676",
                "human": "4.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.934",
                "llava": "0.625",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00155": {
        "id": "00155",
        "prompt": "Three books are stacked on top of each other, with the red one at the bottom, the yellow one in the middle, and the blue one on top.",
        "prompt in Chinese": "\u4e09\u672c\u4e66\u53e0\u5728\u4e00\u8d77\uff0c\u7ea2\u8272\u7684\u4e66\u5728\u6700\u4e0b\u9762\uff0c\u9ec4\u8272\u7684\u4e66\u5728\u4e2d\u95f4\uff0c\u84dd\u8272\u7684\u4e66\u5728\u6700\u4e0a\u9762\u3002\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.928",
                "llava": "0.618",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.971",
                "llava": "0.732",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.814",
                "llava": "0.536",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.893",
                "llava": "0.651",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00156": {
        "id": "00156",
        "prompt": "One bird singing, two flowers swaying.",
        "prompt in Chinese": "\u4e00\u53ea\u9e1f\u5728\u5531\u6b4c\uff0c\u4e24\u6735\u82b1\u5728\u6447\u6446\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.565",
                "llava": "0.314",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.860",
                "llava": "0.385",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.599",
                "llava": "0.466",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.504",
                "llava": "0.296",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00078": {
        "id": "00078",
        "prompt": "A white sailboat drifting towards the left on a calm lake.",
        "prompt in Chinese": "\u4e00\u53ea\u767d\u8272\u5e06\u8239\u5728\u5e73\u9759\u7684\u6e56\u9762\u4e0a\u5411\u5de6\u6f02\u79fb\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.900",
                "llava": "0.680",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.896",
                "llava": "0.646",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.895",
                "llava": "0.655",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.948",
                "llava": "0.595",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00304": {
        "id": "304",
        "prompt": "A girl with pigtails holding a giant sunflower.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.960",
                "llava": "0.756",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.860",
                "llava": "0.350",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.940",
                "llava": "0.816",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.955",
                "llava": "0.766",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00054": {
        "id": "00054",
        "prompt": "An oasis mirage with an ice palace reflecting moonlight in the desert.",
        "prompt in Chinese": "\u6c99\u6f20\u4e2d\u7684\u7eff\u6d32\u5e7b\u89c9\uff0c\u51b0\u5bab\u5728\u6708\u5149\u4e0b\u6620\u7167\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.787",
                "llava": "0.546",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.865",
                "llava": "0.454",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.512",
                "llava": "0.437",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.848",
                "llava": "0.549",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            }
        }
    },
    "00091": {
        "id": "00091",
        "prompt": "Worn-out boots sit on a muddy path, the dense forest looming around them.",
        "prompt in Chinese": "\u78e8\u635f\u7684\u9774\u5b50\u5728\u6ce5\u6cde\u7684\u5c0f\u5f84\u4e0a\uff0c\u5468\u56f4\u662f\u8302\u5bc6\u7684\u68ee\u6797\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.949",
                "llava": "0.716",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.632",
                "llava": "0.382",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.785",
                "llava": "0.511",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.933",
                "llava": "0.668",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00363": {
        "id": "363",
        "prompt": "Two kites flying high in the sky, the dragon-shaped one flies higher and is more colorful than the geometric-patterned one.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.872",
                "llava": "0.578",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.870",
                "llava": "0.602",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.754",
                "llava": "0.419",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.775",
                "llava": "0.651",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "3"
            }
        }
    },
    "00063": {
        "id": "00063",
        "prompt": "A knight with a feather plume helmet by a stone tower.",
        "prompt in Chinese": "\u4e00\u4e2a\u7a7f\u7740\u7fbd\u6bdb\u7fbd\u9970\u5934\u76d4\u7684\u9a91\u58eb\u7ad9\u5728\u77f3\u5854\u65c1\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.916",
                "llava": "0.559",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.957",
                "llava": "0.728",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.964",
                "llava": "0.696",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.625",
                "llava": "0.466",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00317": {
        "id": "317",
        "prompt": "A gardener pruning roses in a vibrant garden.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.959",
                "llava": "0.717",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.954",
                "llava": "0.743",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.971",
                "llava": "0.744",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.792",
                "llava": "0.462",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00150": {
        "id": "00150",
        "prompt": "Three pink peonies and four white daisies in a garden.",
        "prompt in Chinese": "\u82b1\u56ed\u91cc\u6709\u4e09\u6735\u7c89\u7ea2\u8272\u7684\u7261\u4e39\u548c\u56db\u6735\u767d\u8272\u7684\u96cf\u83ca\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.466",
                "llava": "0.383",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.738",
                "llava": "0.382",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.501",
                "llava": "0.253",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.645",
                "llava": "0.327",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00339": {
        "id": "339",
        "prompt": "A ghost hunter investigating an abandoned mansion.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.728",
                "llava": "0.461",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.790",
                "llava": "0.542",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.748",
                "llava": "0.549",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.594",
                "llava": "0.304",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00016": {
        "id": "00016",
        "prompt": "A celestial comet racing across a star-studded, velvet sky.",
        "prompt in Chinese": "\u4e00\u9897\u5929\u4f53\u5f57\u661f\u5728\u6ee1\u662f\u661f\u661f\u7684\u5929\u9e45\u7ed2\u822c\u7684\u591c\u7a7a\u4e2d\u98de\u9a70\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.863",
                "llava": "0.569",
                "human": "1.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.954",
                "llava": "0.614",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.800",
                "llava": "0.551",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.759",
                "llava": "0.642",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "3"
            }
        }
    },
    "00146": {
        "id": "00146",
        "prompt": "One sun setting behind two tall buildings.",
        "prompt in Chinese": "\u4e00\u8f6e\u5915\u9633\u843d\u5728\u4e24\u5ea7\u9ad8\u697c\u7684\u540e\u9762\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.924",
                "llava": "0.632",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.907",
                "llava": "0.668",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.935",
                "llava": "0.711",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.906",
                "llava": "0.666",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00511": {
        "id": "511",
        "prompt": "Four cupcakes with sprinkles on a plate with two forks.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.297",
                "llava": "0.225",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.937",
                "llava": "0.486",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.655",
                "llava": "0.360",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.418",
                "llava": "0.250",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00167": {
        "id": "00167",
        "prompt": "One person makes a humorous face as another watches.",
        "prompt in Chinese": "\u4e00\u4e2a\u4eba\u505a\u7740\u5e7d\u9ed8\u7684\u8868\u60c5\uff0c\u53e6\u4e00\u4e2a\u4eba\u5728\u89c2\u770b\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.785",
                "llava": "0.663",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.878",
                "llava": "0.637",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.897",
                "llava": "0.561",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.912",
                "llava": "0.626",
                "human": "1.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00149": {
        "id": "00149",
        "prompt": "Eight wavy lines are under three polygonal signs.",
        "prompt in Chinese": "\u4e09\u4e2a\u591a\u8fb9\u5f62\u7684\u6807\u5fd7\u4e0b\u9762\u6709\u516b\u6761\u6ce2\u6d6a\u7ebf\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.570",
                "llava": "0.404",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.800",
                "llava": "0.385",
                "human": "1.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.716",
                "llava": "0.460",
                "human": "1.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.365",
                "llava": "0.225",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00510": {
        "id": "510",
        "prompt": "Two bicycles leaning against a wall with three windows.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.354",
                "llava": "0.366",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.962",
                "llava": "0.624",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.896",
                "llava": "0.596",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.943",
                "llava": "0.595",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00338": {
        "id": "338",
        "prompt": "A wizard casting a spell with a wand in a mystical forest.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.970",
                "llava": "0.667",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.966",
                "llava": "0.656",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.805",
                "llava": "0.565",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.691",
                "llava": "0.571",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00143": {
        "id": "00143",
        "prompt": "One orange kite and four white seagulls flying above the beach.",
        "prompt in Chinese": "\u4e00\u4e2a\u6a59\u8272\u7684\u98ce\u7b5d\u548c\u56db\u53ea\u767d\u8272\u7684\u6d77\u9e25\u5728\u6d77\u6ee9\u4e0a\u7a7a\u98de\u7fd4\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.620",
                "llava": "0.192",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.803",
                "llava": "0.402",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.201",
                "llava": "0.214",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.483",
                "llava": "0.326",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00407": {
        "id": "407",
        "prompt": "A snowy forest glistens with delicate ice crystals adorning every branch.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.862",
                "llava": "0.649",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.937",
                "llava": "0.712",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.955",
                "llava": "0.708",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.891",
                "llava": "0.611",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00161": {
        "id": "00161",
        "prompt": "A scene with two blue balls amidst many yellow ones.",
        "prompt in Chinese": "\u5728\u8bb8\u591a\u9ec4\u8272\u7684\u7403\u4e2d\u6709\u4e24\u4e2a\u84dd\u8272\u7684\u7403\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.897",
                "llava": "0.576",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.739",
                "llava": "0.535",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.610",
                "llava": "0.427",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.738",
                "llava": "0.484",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00141": {
        "id": "00141",
        "prompt": "Four flowers blooming, two beside a bench.",
        "prompt in Chinese": "\u56db\u6735\u76db\u5f00\u7684\u82b1\uff0c\u4e24\u6735\u5728\u957f\u6905\u65c1\u8fb9\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.884",
                "llava": "0.591",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.855",
                "llava": "0.622",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.857",
                "llava": "0.584",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.777",
                "llava": "0.615",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "3"
            }
        }
    },
    "00514": {
        "id": "514",
        "prompt": "Six pencils lined up next to one sharpener.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.555",
                "llava": "0.314",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.722",
                "llava": "0.377",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.784",
                "llava": "0.413",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.190",
                "llava": "0.189",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00069": {
        "id": "00069",
        "prompt": "A fairy with butterfly wings in a dewy meadow.",
        "prompt in Chinese": "\u9732\u6c34\u8349\u5730\u4e0a\u957f\u7740\u8774\u8776\u7fc5\u8180\u7684\u4ed9\u5973\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.870",
                "llava": "0.618",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.963",
                "llava": "0.759",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.967",
                "llava": "0.731",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.897",
                "llava": "0.631",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00204": {
        "id": "00204",
        "prompt": "a person without a hat pushes a person with a hat sitting in a box.",
        "prompt in Chinese": "\u4e00\u4e2a\u6ca1\u6709\u6234\u5e3d\u5b50\u7684\u4eba\u63a8\u7740\u4e00\u4e2a\u5750\u5728\u76d2\u5b50\u91cc\u7684\u6234\u5e3d\u5b50\u7684\u4eba\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.583",
                "llava": "0.304",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.103",
                "llava": "0.206",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.744",
                "llava": "0.339",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.777",
                "llava": "0.411",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00508": {
        "id": "508",
        "prompt": "Six birds soar above two towering trees.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.837",
                "llava": "0.450",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.692",
                "llava": "0.321",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.571",
                "llava": "0.372",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.367",
                "llava": "0.380",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00115": {
        "id": "00115",
        "prompt": "A scene where there are more hats than stools.",
        "prompt in Chinese": "\u4e00\u4e2a\u573a\u666f\u91cc\uff0c\u5e3d\u5b50\u6bd4\u51f3\u5b50\u591a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.915",
                "llava": "0.643",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.902",
                "llava": "0.619",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.891",
                "llava": "0.805",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.925",
                "llava": "0.623",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00244": {
        "id": "00244",
        "prompt": "In a mysterious forest, the leaves of a green tree shimmer with silvery glow, contrasting the dim leaves of a nearby red tree.",
        "prompt in Chinese": "\u5728\u4e00\u4e2a\u795e\u79d8\u7684\u68ee\u6797\u91cc\uff0c\u4e00\u68f5\u7eff\u6811\u7684\u53f6\u5b50\u95ea\u7740\u94f6\u8272\u7684\u5149\u8292\uff0c\u4e0e\u9644\u8fd1\u4e00\u68f5\u7ea2\u6811\u6697\u6de1\u7684\u53f6\u5b50\u5f62\u6210\u5bf9\u6bd4\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.848",
                "llava": "0.625",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.876",
                "llava": "0.645",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.814",
                "llava": "0.633",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.666",
                "llava": "0.380",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00462": {
        "id": "462",
        "prompt": "Two trees standing tall; one is leafy, and the other is not.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.836",
                "llava": "0.653",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.807",
                "llava": "0.621",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.840",
                "llava": "0.545",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.837",
                "llava": "0.581",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00203": {
        "id": "00203",
        "prompt": "the pet on the right is blue and the one on the left is not.",
        "prompt in Chinese": "\u53f3\u8fb9\u7684\u5ba0\u7269\u662f\u84dd\u8272\u7684\uff0c\u5de6\u8fb9\u7684\u5ba0\u7269\u4e0d\u662f\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.807",
                "llava": "0.692",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.878",
                "llava": "0.569",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.919",
                "llava": "0.716",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.934",
                "llava": "0.647",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00129": {
        "id": "00129",
        "prompt": "A garden scene, weeds growing on the left side of the garden while the right side is neatly manicured.",
        "prompt in Chinese": "\u4e00\u4e2a\u82b1\u56ed\u573a\u666f\uff0c\u82b1\u56ed\u7684\u5de6\u8fb9\u957f\u6ee1\u4e86\u6742\u8349\uff0c\u800c\u53f3\u8fb9\u5219\u4fee\u526a\u5f97\u6574\u6574\u9f50\u9f50\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.829",
                "llava": "0.673",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.879",
                "llava": "0.637",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.677",
                "llava": "0.491",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.909",
                "llava": "0.589",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00392": {
        "id": "392",
        "prompt": "A small pond with a black swan on the left and a white swan on the right.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.927",
                "llava": "0.628",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.496",
                "llava": "0.353",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.935",
                "llava": "0.660",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.410",
                "llava": "0.224",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00330": {
        "id": "330",
        "prompt": "A street performer juggling fire torches at night.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.957",
                "llava": "0.716",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.972",
                "llava": "0.756",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.947",
                "llava": "0.675",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.928",
                "llava": "0.757",
                "human": "4.67",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00318": {
        "id": "318",
        "prompt": "Two joggers running along a misty riverbank at dawn.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.947",
                "llava": "0.655",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.966",
                "llava": "0.619",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.895",
                "llava": "0.645",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.150",
                "llava": "0.143",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00426": {
        "id": "426",
        "prompt": "Among all the cars in the parking lot, each one is parked neatly except for one that is askew.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.671",
                "llava": "0.506",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.700",
                "llava": "0.486",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.689",
                "llava": "0.491",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.775",
                "llava": "0.461",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00370": {
        "id": "370",
        "prompt": "Two children laugh joyfully, the bigger one holding a balloon, the other clutching a toy.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.926",
                "llava": "0.630",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.872",
                "llava": "0.648",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.895",
                "llava": "0.608",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.374",
                "llava": "0.304",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00039": {
        "id": "00039",
        "prompt": "A cat basking in the sunlight by a window.",
        "prompt in Chinese": "\u4e00\u53ea\u732b\u5728\u7a97\u8fb9\u9633\u5149\u4e0b\u6652\u592a\u9633\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.973",
                "llava": "0.765",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.963",
                "llava": "0.739",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.980",
                "llava": "0.781",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.935",
                "llava": "0.690",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00181": {
        "id": "00181",
        "prompt": "A bird chirping melodiously on the right, with another listening intently on the left.",
        "prompt in Chinese": "\u4e00\u53ea\u9e1f\u5728\u53f3\u8fb9\u5a49\u8f6c\u5730\u9e23\u53eb\uff0c\u53e6\u4e00\u53ea\u9e1f\u5728\u5de6\u8fb9\u4e13\u6ce8\u5730\u503e\u542c\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.629",
                "llava": "0.503",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.838",
                "llava": "0.462",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.711",
                "llava": "0.528",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.577",
                "llava": "0.388",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00219": {
        "id": "00219",
        "prompt": "A modern home office setup, a computer monitor on the desk showing a digital calendar with 'Meeting at 3 PM' highlighted.",
        "prompt in Chinese": "\u4e00\u4e2a\u73b0\u4ee3\u5bb6\u5ead\u529e\u516c\u5ba4\u5e03\u7f6e\uff0c\u684c\u5b50\u4e0a\u7684\u7535\u8111\u663e\u793a\u5668\u663e\u793a\u7740\u4e00\u4e2a\u6570\u5b57\u65e5\u5386\uff0c\u5176\u4e2d'Meeting at 3 PM'\u88ab\u7a81\u51fa\u663e\u793a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.723",
                "llava": "0.570",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.957",
                "llava": "0.730",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.888",
                "llava": "0.673",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.793",
                "llava": "0.520",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00257": {
        "id": "00257",
        "prompt": "An aquarium where every tank is home to a multitude of colorful fish, swimming in harmony.",
        "prompt in Chinese": "\u6c34\u65cf\u9986\u91cc\uff0c\u6bcf\u4e2a\u9c7c\u7f38\u91cc\u90fd\u6709\u8bb8\u591a\u8272\u5f69\u6591\u6593\u7684\u9c7c\u513f\uff0c\u5b83\u4eec\u548c\u8c10\u5730\u6e38\u52a8\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.821",
                "llava": "0.616",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.825",
                "llava": "0.613",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.861",
                "llava": "0.618",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.733",
                "llava": "0.530",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00288": {
        "id": "00288",
        "prompt": "A boy and a dog standing in the desert.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.989",
                "llava": "0.774",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.986",
                "llava": "0.795",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.975",
                "llava": "0.743",
                "human": "4.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.977",
                "llava": "0.758",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00433": {
        "id": "433",
        "prompt": "A tree with no leaves, only shadows beneath.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.824",
                "llava": "0.652",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.881",
                "llava": "0.676",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.932",
                "llava": "0.669",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.827",
                "llava": "0.610",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00326": {
        "id": "326",
        "prompt": "A jogger and their dog running on the beach.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.355",
                "llava": "0.297",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.965",
                "llava": "0.679",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.958",
                "llava": "0.665",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.942",
                "llava": "0.724",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            }
        }
    },
    "00180": {
        "id": "00180",
        "prompt": "Adjacent houses stand side by side; the left one sports a chimney, while the right one has none.",
        "prompt in Chinese": "\u76f8\u90bb\u7684\u623f\u5b50\u5e76\u6392\u800c\u7acb\uff0c\u5de6\u8fb9\u7684\u623f\u5b50\u6709\u70df\u56f1\uff0c\u53f3\u8fb9\u7684\u623f\u5b50\u6ca1\u6709\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.755",
                "llava": "0.555",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.901",
                "llava": "0.649",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.746",
                "llava": "0.506",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.690",
                "llava": "0.528",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00411": {
        "id": "411",
        "prompt": "Orange juice and toast on every breakfast table.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.707",
                "llava": "0.455",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.719",
                "llava": "0.482",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.667",
                "llava": "0.548",
                "human": "4.67",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.757",
                "llava": "0.515",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00198": {
        "id": "00198",
        "prompt": "six people wear white shirts and no people wear red shirts.",
        "prompt in Chinese": "\u516d\u4e2a\u4eba\u7a7f\u767d\u886c\u886b\uff0c\u6ca1\u6709\u4eba\u7a7f\u7ea2\u886c\u886b\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.937",
                "llava": "0.610",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.633",
                "llava": "0.448",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.415",
                "llava": "0.285",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.571",
                "llava": "0.372",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00394": {
        "id": "394",
        "prompt": "A large pizza with pepperoni on the left half and mushrooms on the right half.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.772",
                "llava": "0.421",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.873",
                "llava": "0.720",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.817",
                "llava": "0.674",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.849",
                "llava": "0.657",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00137": {
        "id": "00137",
        "prompt": "A child studying at a table, the left side of the table is neat, but the right side is cluttered.",
        "prompt in Chinese": "\u4e00\u4e2a\u5b69\u5b50\u5728\u684c\u5b50\u65c1\u5b66\u4e60\uff0c\u684c\u5b50\u5de6\u8fb9\u6574\u6d01\uff0c\u53f3\u8fb9\u6742\u4e71\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.833",
                "llava": "0.601",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.743",
                "llava": "0.607",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.936",
                "llava": "0.705",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.761",
                "llava": "0.525",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00376": {
        "id": "376",
        "prompt": "Two birds perch on a branch, the happy one chirping loudly, the sad one listening silently.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.679",
                "llava": "0.537",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.627",
                "llava": "0.492",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.627",
                "llava": "0.263",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.480",
                "llava": "0.286",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00138": {
        "id": "00138",
        "prompt": "At the center of the table,  four gleaming silver forks encircle a solitary porcelain plate.",
        "prompt in Chinese": "\u5728\u684c\u5b50\u4e2d\u592e\uff0c\u56db\u628a\u95ea\u4eae\u7684\u94f6\u53c9\u56f4\u7ed5\u7740\u4e00\u4e2a\u74f7\u76d8\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.861",
                "llava": "0.617",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.866",
                "llava": "0.627",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.777",
                "llava": "0.673",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.891",
                "llava": "0.654",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00305": {
        "id": "305",
        "prompt": "A skateboarder performing a trick in an urban skate park.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.907",
                "llava": "0.713",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.950",
                "llava": "0.716",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.964",
                "llava": "0.731",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.907",
                "llava": "0.749",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00395": {
        "id": "395",
        "prompt": "A red rose in full bloom next to a pink rosebud in a garden.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.543",
                "llava": "0.566",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.905",
                "llava": "0.757",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.775",
                "llava": "0.338",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.705",
                "llava": "0.449",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00417": {
        "id": "417",
        "prompt": "Several cups on a round table and all the cups are incomplete.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.611",
                "llava": "0.443",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.735",
                "llava": "0.447",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.773",
                "llava": "0.468",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.726",
                "llava": "0.672",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00235": {
        "id": "00235",
        "prompt": "'Jazz Night' flashing on a neon sign at the entrance to the Music Lounge.",
        "prompt in Chinese": "'Jazz Night'\u5728\u97f3\u4e50\u4f11\u606f\u5ba4\u5165\u53e3\u5904\u7684\u9713\u8679\u706f\u724c\u4e0a\u95ea\u70c1\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.615",
                "llava": "0.490",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.881",
                "llava": "0.715",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.799",
                "llava": "0.561",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.589",
                "llava": "0.308",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00114": {
        "id": "00114",
        "prompt": "An interior space with stools outnumbering the people.",
        "prompt in Chinese": "\u4e00\u4e2a\u5ba4\u5185\u7a7a\u95f4\u91cc\uff0c\u51f3\u5b50\u7684\u6570\u91cf\u8d85\u8fc7\u4e86\u4eba\u6570\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.881",
                "llava": "0.662",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.858",
                "llava": "0.634",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.836",
                "llava": "0.684",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.874",
                "llava": "0.665",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00206": {
        "id": "00206",
        "prompt": "There are some apples on the table, no oranges.",
        "prompt in Chinese": "\u684c\u5b50\u4e0a\u6709\u4e00\u4e9b\u82f9\u679c\uff0c\u6ca1\u6709\u6a59\u5b50\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.924",
                "llava": "0.703",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.915",
                "llava": "0.783",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.925",
                "llava": "0.764",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.910",
                "llava": "0.630",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00441": {
        "id": "441",
        "prompt": "A painting with no colors, only shades of gray.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.722",
                "llava": "0.655",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.845",
                "llava": "0.649",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.879",
                "llava": "0.574",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.942",
                "llava": "0.718",
                "human": "1.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            }
        }
    },
    "00517": {
        "id": "517",
        "prompt": "Three snowmen standing in a garden with two pine trees.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.868",
                "llava": "0.561",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.722",
                "llava": "0.626",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.847",
                "llava": "0.603",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.707",
                "llava": "0.572",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00160": {
        "id": "00160",
        "prompt": "An excited cat is on the left and an upset cat is on the right",
        "prompt in Chinese": "\u4e00\u53ea\u5174\u594b\u7684\u732b\u5728\u5de6\u8fb9\uff0c\u4e00\u53ea\u4e0d\u9ad8\u5174\u7684\u732b\u5728\u53f3\u8fb9",
        "models": {
            "Floor33": {
                "clip_flant5": "0.360",
                "llava": "0.234",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.415",
                "llava": "0.238",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.570",
                "llava": "0.307",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.429",
                "llava": "0.215",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00065": {
        "id": "00065",
        "prompt": "A swan with a silver anklet on a crystal lake.",
        "prompt in Chinese": "\u4e00\u53ea\u5728\u6c34\u6676\u6e56\u4e0a\u6234\u7740\u94f6\u8272\u811a\u94fe\u7684\u5929\u9e45\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.599",
                "llava": "0.361",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.555",
                "llava": "0.414",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.595",
                "llava": "0.380",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.665",
                "llava": "0.486",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00311": {
        "id": "311",
        "prompt": "A surfer riding a large wave at sunset.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.979",
                "llava": "0.750",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.964",
                "llava": "0.795",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.974",
                "llava": "0.772",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.863",
                "llava": "0.691",
                "human": "4.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00109": {
        "id": "00109",
        "prompt": "In a gym, there are two people, the one closer to the table is resting and the one further away from the table is lifting weights.",
        "prompt in Chinese": "\u5728\u5065\u8eab\u623f\u91cc\uff0c\u6709\u4e24\u4e2a\u4eba\uff0c\u79bb\u684c\u5b50\u8fd1\u7684\u5728\u4f11\u606f\uff0c\u79bb\u684c\u5b50\u8fdc\u7684\u5728\u4e3e\u91cd\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.723",
                "llava": "0.548",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.875",
                "llava": "0.710",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.889",
                "llava": "0.702",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.898",
                "llava": "0.654",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00345": {
        "id": "345",
        "prompt": "A sailboat drifts lazily along the river, with swans paddling gently beside it and willows weeping at its banks.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.560",
                "llava": "0.534",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.921",
                "llava": "0.707",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.874",
                "llava": "0.692",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.855",
                "llava": "0.507",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00518": {
        "id": "518",
        "prompt": "Two clouds casting shadows over three sunflowers.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.534",
                "llava": "0.316",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.558",
                "llava": "0.388",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.627",
                "llava": "0.209",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.236",
                "llava": "0.273",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00494": {
        "id": "494",
        "prompt": "A starry night sky with more visible stars than the number of lights in the city below.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.735",
                "llava": "0.579",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.861",
                "llava": "0.639",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.738",
                "llava": "0.642",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.865",
                "llava": "0.573",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00483": {
        "id": "483",
        "prompt": "Two cups on the table; one is full, but the other is not.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.869",
                "llava": "0.614",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.450",
                "llava": "0.244",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.879",
                "llava": "0.674",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.828",
                "llava": "0.728",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00468": {
        "id": "468",
        "prompt": "A pair of shoes, one tied and the other not.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.827",
                "llava": "0.602",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.840",
                "llava": "0.707",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.766",
                "llava": "0.620",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.922",
                "llava": "0.666",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            }
        }
    },
    "00223": {
        "id": "00223",
        "prompt": "A serene beach scene at sunset with 'Paradise Awaits' written in the sand, the ocean gently lapping at the letters.",
        "prompt in Chinese": "\u65e5\u843d\u65f6\u5206\u7684\u5b81\u9759\u6d77\u6ee9\u573a\u666f\uff0c\u6c99\u6ee9\u4e0a\u5199\u7740 'Paradise Awaits'\uff0c\u6d77\u6d6a\u8f7b\u8f7b\u62cd\u6253\u7740\u5b57\u6bcd\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.884",
                "llava": "0.626",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.885",
                "llava": "0.737",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.955",
                "llava": "0.677",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.288",
                "llava": "0.214",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00121": {
        "id": "00121",
        "prompt": "A map unfolds widely on the wall and a compass points northward.",
        "prompt in Chinese": "\u4e00\u5e45\u5730\u56fe\u5728\u5899\u4e0a\u5c55\u5f00\uff0c\u6307\u5357\u9488\u6307\u5411\u5317\u65b9\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.593",
                "llava": "0.594",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.695",
                "llava": "0.514",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.931",
                "llava": "0.710",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.854",
                "llava": "0.498",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00367": {
        "id": "367",
        "prompt": "Among the two cups on the desk, the taller one holds more coffee than the shorter, which is half-empty.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.707",
                "llava": "0.573",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.670",
                "llava": "0.506",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.599",
                "llava": "0.410",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.640",
                "llava": "0.371",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00004": {
        "id": "00004",
        "prompt": "A man shaping clay on a wheel in a cluttered workshop.",
        "prompt in Chinese": "\u4e00\u4f4d\u7537\u58eb\u5728\u4e00\u4e2a\u6742\u4e71\u7684\u5de5\u4f5c\u5ba4\u91cc\u5728\u9676\u8f6e\u4e0a\u5851\u5f62\u9ecf\u571f\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.917",
                "llava": "0.733",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.921",
                "llava": "0.798",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.982",
                "llava": "0.778",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.953",
                "llava": "0.709",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00384": {
        "id": "384",
        "prompt": "A black cat sits on a window sill, while a white cat lies beneath the sill in the sunlight.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.788",
                "llava": "0.618",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.192",
                "llava": "0.206",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.190",
                "llava": "0.167",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.799",
                "llava": "0.226",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00519": {
        "id": "519",
        "prompt": "Two apples on a kitchen counter.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.977",
                "llava": "0.775",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.978",
                "llava": "0.874",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.899",
                "llava": "0.681",
                "human": "4.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.941",
                "llava": "0.725",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00323": {
        "id": "323",
        "prompt": "A child hunting for treasure with a metal detector on the beach.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.858",
                "llava": "0.490",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.749",
                "llava": "0.439",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.480",
                "llava": "0.417",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.494",
                "llava": "0.497",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "4"
            }
        }
    },
    "00228": {
        "id": "00228",
        "prompt": "'Book Nook' carved on a small library door, lantern-lit beside.",
        "prompt in Chinese": "\u4e00\u4e2a\u5c0f\u56fe\u4e66\u9986\u7684\u95e8\u4e0a\u96d5\u523b\u7740'Book Nook'\uff0c\u65c1\u8fb9\u70b9\u7740\u706f\u7b3c\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.839",
                "llava": "0.578",
                "human": "1.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.648",
                "llava": "0.435",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.658",
                "llava": "0.531",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.515",
                "llava": "0.380",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00414": {
        "id": "414",
        "prompt": "Leaves falling on every car in the autumn.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.481",
                "llava": "0.425",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.626",
                "llava": "0.375",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.716",
                "llava": "0.534",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.577",
                "llava": "0.331",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00347": {
        "id": "347",
        "prompt": "A wilderness scene, wildflowers blooming on the right while a dense forest stands to the left.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.897",
                "llava": "0.696",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.955",
                "llava": "0.785",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.901",
                "llava": "0.745",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.917",
                "llava": "0.713",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00520": {
        "id": "520",
        "prompt": "Three birds sitting on a wire.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.973",
                "llava": "0.860",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.726",
                "llava": "0.477",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.969",
                "llava": "0.816",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.967",
                "llava": "0.751",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00077": {
        "id": "00077",
        "prompt": "A small pond with a single swan gliding towards the left.",
        "prompt in Chinese": "\u4e00\u4e2a\u5c0f\u6c60\u5858\u91cc\uff0c\u4e00\u53ea\u5929\u9e45\u5411\u5de6\u6ed1\u884c\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.817",
                "llava": "0.636",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.782",
                "llava": "0.636",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.902",
                "llava": "0.704",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.893",
                "llava": "0.690",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00481": {
        "id": "481",
        "prompt": "A pair of socks, one is striped, but the other is not.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.930",
                "llava": "0.714",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.833",
                "llava": "0.675",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.876",
                "llava": "0.706",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.923",
                "llava": "0.742",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00509": {
        "id": "509",
        "prompt": "Four children jumping rope in the park",
        "models": {
            "Floor33": {
                "clip_flant5": "0.354",
                "llava": "0.215",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.886",
                "llava": "0.557",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.544",
                "llava": "0.522",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.662",
                "llava": "0.430",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00021": {
        "id": "00021",
        "prompt": "A lantern casting spectral light in a haunted, whispering forest.",
        "prompt in Chinese": "\u4e00\u76cf\u706f\u5728\u4e00\u4e2a\u95f9\u9b3c\u3001\u4f4e\u8bed\u7684\u68ee\u6797\u4e2d\u6563\u53d1\u5e7d\u5149\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.860",
                "llava": "0.638",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.760",
                "llava": "0.561",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.897",
                "llava": "0.670",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.693",
                "llava": "0.621",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00030": {
        "id": "00030",
        "prompt": "An old person snips a blooming rose.",
        "prompt in Chinese": "\u4e00\u4e2a\u8001\u4eba\u526a\u4e0b\u4e00\u6735\u76db\u5f00\u7684\u73ab\u7470\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.790",
                "llava": "0.622",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.964",
                "llava": "0.656",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.458",
                "llava": "0.519",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.838",
                "llava": "0.535",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00432": {
        "id": "432",
        "prompt": "All the doors in the hallway are closed, except for one that is slightly ajar.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.814",
                "llava": "0.593",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.773",
                "llava": "0.587",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.775",
                "llava": "0.619",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.798",
                "llava": "0.647",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "4"
            }
        }
    },
    "00230": {
        "id": "00230",
        "prompt": "A 'Veggie Patch' sign staked in a garden, lush greens around.",
        "prompt in Chinese": "\u4e00\u5757'Veggie Patch'\u7684\u62db\u724c\u7acb\u5728\u82b1\u56ed\u91cc\uff0c\u5468\u56f4\u7eff\u610f\u76ce\u7136\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.953",
                "llava": "0.752",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.958",
                "llava": "0.758",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.965",
                "llava": "0.780",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.785",
                "llava": "0.657",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00289": {
        "id": "00289",
        "prompt": "A boy and a dog standing in the beach.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.819",
                "llava": "0.486",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.563",
                "llava": "0.572",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.982",
                "llava": "0.729",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.381",
                "llava": "0.246",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00375": {
        "id": "375",
        "prompt": "Two cats sit at the window, the blue one intently watching the rain, the red one curled up asleep.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.725",
                "llava": "0.427",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.422",
                "llava": "0.466",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.549",
                "llava": "0.471",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.756",
                "llava": "0.376",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00277": {
        "id": "00277",
        "prompt": "A young lady wearing a T-shirt puts her hand on a puppy's paw.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.924",
                "llava": "0.681",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.978",
                "llava": "0.821",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.822",
                "llava": "0.679",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.865",
                "llava": "0.702",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00258": {
        "id": "00258",
        "prompt": "In a square, several children are playing, each wearing a red T-shirt.",
        "prompt in Chinese": "\u5728\u4e00\u4e2a\u5e7f\u573a\u4e0a,\u51e0\u4e2a\u5b69\u5b50\u6b63\u5728\u73a9\u800d,\u6bcf\u4e2a\u4eba\u90fd\u7a7f\u7740\u7ea2\u8272T\u6064\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.687",
                "llava": "0.638",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.961",
                "llava": "0.734",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.863",
                "llava": "0.697",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.905",
                "llava": "0.662",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00162": {
        "id": "00162",
        "prompt": "Cats playing on the roof, the cat on the left has curly hair, the cat on the right has straight hair",
        "prompt in Chinese": "\u732b\u5728\u5c4b\u9876\u4e0a\u73a9\u800d\uff0c\u5de6\u8fb9\u7684\u732b\u662f\u5377\u6bdb\uff0c\u53f3\u8fb9\u7684\u732b\u662f\u76f4\u6bdb",
        "models": {
            "Floor33": {
                "clip_flant5": "0.133",
                "llava": "0.212",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.819",
                "llava": "0.541",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.818",
                "llava": "0.501",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.585",
                "llava": "0.416",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00499": {
        "id": "499",
        "prompt": "A painting where the mountain is depicted as taller than the trees in the foreground.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.671",
                "llava": "0.632",
                "human": "4.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.820",
                "llava": "0.674",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.923",
                "llava": "0.715",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.863",
                "llava": "0.572",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00351": {
        "id": "351",
        "prompt": "A notebook lies open in the grass, with sketches on the left page and blank space on the right.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.613",
                "llava": "0.545",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.880",
                "llava": "0.541",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.886",
                "llava": "0.746",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.911",
                "llava": "0.776",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            }
        }
    },
    "00183": {
        "id": "00183",
        "prompt": "An old artist holding a paintbrush faces a young artist wielding a pencil.",
        "prompt in Chinese": "\u4e00\u4f4d\u62ff\u7740\u753b\u7b14\u7684\u8001\u827a\u672f\u5bb6\u9762\u5bf9\u7740\u4e00\u4f4d\u624b\u6301\u94c5\u7b14\u7684\u5e74\u8f7b\u827a\u672f\u5bb6\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.835",
                "llava": "0.592",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.642",
                "llava": "0.459",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.853",
                "llava": "0.693",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.592",
                "llava": "0.500",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00316": {
        "id": "316",
        "prompt": "A cyclist racing down a winding mountain path.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.968",
                "llava": "0.800",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.923",
                "llava": "0.747",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.955",
                "llava": "0.784",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.928",
                "llava": "0.771",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00240": {
        "id": "00240",
        "prompt": "A small dog with wings, wearing a bell around its neck that is bigger than itself.",
        "prompt in Chinese": "\u4e00\u53ea\u6709\u7fc5\u8180\u7684\u5c0f\u72d7\uff0c\u8116\u5b50\u4e0a\u6234\u7740\u4e00\u4e2a\u6bd4\u81ea\u5df1\u8fd8\u5927\u7684\u94c3\u94db\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.634",
                "llava": "0.445",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.826",
                "llava": "0.707",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.812",
                "llava": "0.633",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.507",
                "llava": "0.324",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00144": {
        "id": "00144",
        "prompt": "Five enthusiastic athletes and one tired coach.",
        "prompt in Chinese": "\u4e94\u4e2a\u5145\u6ee1\u70ed\u60c5\u7684\u8fd0\u52a8\u5458\u548c\u4e00\u4e2a\u75b2\u60eb\u7684\u6559\u7ec3\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.301",
                "llava": "0.389",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.518",
                "llava": "0.258",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.601",
                "llava": "0.288",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.471",
                "llava": "0.292",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00247": {
        "id": "00247",
        "prompt": "A mystical forest at twilight, illuminated by three floating orbs, with one unicorn drinking from a clear stream.",
        "prompt in Chinese": "\u66ae\u8272\u4e2d\u7684\u795e\u79d8\u68ee\u6797\uff0c\u88ab\u4e09\u4e2a\u6f02\u6d6e\u7684\u5149\u7403\u7167\u4eae\uff0c\u6709\u4e00\u53ea\u72ec\u89d2\u517d\u5728\u6e05\u6f88\u7684\u6eaa\u6d41\u4e2d\u996e\u6c34\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.678",
                "llava": "0.537",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.567",
                "llava": "0.509",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.927",
                "llava": "0.719",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.846",
                "llava": "0.596",
                "human": "1.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00475": {
        "id": "475",
        "prompt": "Two car in the street, the car on the left is red, but the one on the right is not.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.576",
                "llava": "0.466",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.696",
                "llava": "0.616",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.857",
                "llava": "0.673",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.810",
                "llava": "0.527",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00321": {
        "id": "321",
        "prompt": "A nurse comforting a patient in a hospital room.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.604",
                "llava": "0.575",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.962",
                "llava": "0.758",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.971",
                "llava": "0.805",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.959",
                "llava": "0.705",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00042": {
        "id": "00042",
        "prompt": "Old boots resting on a muddy trail in the woods.",
        "prompt in Chinese": "\u65e7\u9774\u5b50\u505c\u653e\u5728\u6811\u6797\u4e2d\u7684\u6ce5\u6cde\u5c0f\u5f84\u4e0a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.942",
                "llava": "0.763",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.917",
                "llava": "0.804",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.935",
                "llava": "0.774",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.904",
                "llava": "0.707",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00402": {
        "id": "402",
        "prompt": "A rustic wooden bench under a sprawling oak, with a modern metal chair facing it across a stone path.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.736",
                "llava": "0.353",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.225",
                "llava": "0.217",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.233",
                "llava": "0.265",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.501",
                "llava": "0.227",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00092": {
        "id": "00092",
        "prompt": "A bright yellow taxi parked in front, a tall glass building rising behind it amidst clouds.",
        "prompt in Chinese": "\u4e00\u8f86\u660e\u9ec4\u8272\u7684\u51fa\u79df\u8f66\u505c\u5728\u524d\u65b9\uff0c\u8eab\u540e\u662f\u8038\u5165\u4e91\u7aef\u7684\u9ad8\u5927\u73bb\u7483\u5efa\u7b51\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.541",
                "llava": "0.538",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.904",
                "llava": "0.712",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.930",
                "llava": "0.780",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.836",
                "llava": "0.549",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00333": {
        "id": "333",
        "prompt": "A monk meditating beside a tranquil mountain stream.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.952",
                "llava": "0.697",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.982",
                "llava": "0.698",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.950",
                "llava": "0.691",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.069",
                "llava": "0.236",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00425": {
        "id": "425",
        "prompt": "All the books on the shelf are closed, except for one that lies open.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.814",
                "llava": "0.663",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.706",
                "llava": "0.541",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.796",
                "llava": "0.635",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.661",
                "llava": "0.512",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00500": {
        "id": "500",
        "prompt": "A library with more shelves filled with books than empty ones.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.895",
                "llava": "0.750",
                "human": "4.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.911",
                "llava": "0.759",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.927",
                "llava": "0.775",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.909",
                "llava": "0.747",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00496": {
        "id": "496",
        "prompt": "A fruit basket with more apples than oranges.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.711",
                "llava": "0.636",
                "human": "4.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.887",
                "llava": "0.724",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.877",
                "llava": "0.730",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.887",
                "llava": "0.663",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00350": {
        "id": "350",
        "prompt": "A bridge arches over the river, with lanterns lit on one side and the other in darkness.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.760",
                "llava": "0.654",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.935",
                "llava": "0.777",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.953",
                "llava": "0.789",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.574",
                "llava": "0.394",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00233": {
        "id": "00233",
        "prompt": "'Eco Market' on a banner above a green lifestyle fair.",
        "prompt in Chinese": "'Eco Market' \u6a2a\u5e45\u6302\u5728\u4e00\u4e2a\u7eff\u8272\u751f\u6d3b\u65b9\u5f0f\u5c55\u9500\u4f1a\u7684\u4e0a\u65b9\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.316",
                "llava": "0.222",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.962",
                "llava": "0.749",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.815",
                "llava": "0.581",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.679",
                "llava": "0.615",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00123": {
        "id": "00123",
        "prompt": "Three flowers on the ground: one red, another yellow, and the third blue.",
        "prompt in Chinese": "\u5730\u4e0a\u6709\u4e09\u6735\u82b1\uff1a\u4e00\u6735\u7ea2\u8272\uff0c\u53e6\u4e00\u6735\u9ec4\u8272\uff0c\u7b2c\u4e09\u6735\u84dd\u8272\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.773",
                "llava": "0.665",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.885",
                "llava": "0.661",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.950",
                "llava": "0.777",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.651",
                "llava": "0.551",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00221": {
        "id": "00221",
        "prompt": "A typewriter on a wooden desk, paper rolled in displaying the words 'Chapter 1' in classic font.",
        "prompt in Chinese": "\u4e00\u53f0\u6253\u5b57\u673a\u653e\u5728\u6728\u684c\u4e0a\uff0c\u5377\u7740\u7eb8\u5f20\uff0c\u663e\u793a\u7740\u7528\u7ecf\u5178\u5b57\u4f53\u6253\u5370\u7684'Chapter 1'\u5b57\u6837\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.856",
                "llava": "0.607",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.296",
                "llava": "0.465",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.972",
                "llava": "0.746",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.812",
                "llava": "0.517",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00477": {
        "id": "477",
        "prompt": "Two windows in a room; one is open, but the other is not.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.800",
                "llava": "0.663",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.668",
                "llava": "0.588",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.763",
                "llava": "0.567",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.852",
                "llava": "0.665",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00313": {
        "id": "313",
        "prompt": "A dancer in a flowing dress spinning in a spotlight.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.880",
                "llava": "0.667",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.936",
                "llava": "0.740",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.908",
                "llava": "0.724",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.787",
                "llava": "0.787",
                "human": "4.00",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "4"
            }
        }
    },
    "00095": {
        "id": "00095",
        "prompt": "A cat lounging lazily on a sunny windowsill.",
        "prompt in Chinese": "\u4e00\u53ea\u732b\u6175\u61d2\u5730\u8eba\u5728\u9633\u5149\u660e\u5a9a\u7684\u7a97\u53f0\u4e0a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.974",
                "llava": "0.762",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.980",
                "llava": "0.770",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.831",
                "llava": "0.765",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.872",
                "llava": "0.767",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00357": {
        "id": "357",
        "prompt": "There are two men in the living room, the taller one to the left of the shorter one.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.962",
                "llava": "0.717",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.940",
                "llava": "0.785",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.778",
                "llava": "0.472",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.131",
                "llava": "0.245",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00002": {
        "id": "00002",
        "prompt": "A photographer capturing a fleeting moment in a vibrant city street.",
        "prompt in Chinese": "\u4e00\u4f4d\u6444\u5f71\u5e08\u5728\u5145\u6ee1\u6d3b\u529b\u7684\u57ce\u5e02\u8857\u5934\u6355\u6349\u77ac\u95f4\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.681",
                "llava": "0.529",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.978",
                "llava": "0.682",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.656",
                "llava": "0.611",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.487",
                "llava": "0.393",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00079": {
        "id": "00079",
        "prompt": "A single red rose in a vase on the right side of a windowsill.",
        "prompt in Chinese": "\u4e00\u4e2a\u7a97\u53f0\u53f3\u4fa7\u7684\u82b1\u74f6\u4e2d\u6709\u4e00\u6735\u7ea2\u73ab\u7470\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.904",
                "llava": "0.762",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.855",
                "llava": "0.772",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.844",
                "llava": "0.651",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.923",
                "llava": "0.761",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00010": {
        "id": "00010",
        "prompt": "A sorcerer's hat casting shadows over a cluttered, enchanted desk.",
        "prompt in Chinese": "\u4e00\u9876\u5deb\u5e08\u7684\u5e3d\u5b50\u5728\u4e00\u4e2a\u6742\u4e71\u3001\u5145\u6ee1\u9b54\u6cd5\u7684\u4e66\u684c\u4e0a\u6295\u4e0b\u9634\u5f71\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.838",
                "llava": "0.610",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.398",
                "llava": "0.473",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.888",
                "llava": "0.592",
                "human": "1.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.744",
                "llava": "0.614",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            }
        }
    },
    "00446": {
        "id": "446",
        "prompt": "A ball with no bounce, lying still.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.836",
                "llava": "0.669",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.758",
                "llava": "0.733",
                "human": "5.00",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.853",
                "llava": "0.663",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.851",
                "llava": "0.655",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00361": {
        "id": "361",
        "prompt": "There are two shoes on the grass, the one without laces looks newer than the one with laces.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.679",
                "llava": "0.558",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.785",
                "llava": "0.567",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.363",
                "llava": "0.301",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.787",
                "llava": "0.611",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            }
        }
    },
    "00044": {
        "id": "00044",
        "prompt": "An armchair with a knit blanket draped over it, next to a fireplace.",
        "prompt in Chinese": "\u4e00\u628a\u6276\u624b\u6905\u4e0a\u642d\u7740\u4e00\u6761\u9488\u7ec7\u6bef\u5b50\uff0c\u65c1\u8fb9\u662f\u4e00\u4e2a\u58c1\u7089\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.990",
                "llava": "0.830",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.990",
                "llava": "0.826",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.987",
                "llava": "0.847",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.944",
                "llava": "0.834",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00464": {
        "id": "464",
        "prompt": "A bookshelf filled with books, but not a single magazine.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.696",
                "llava": "0.546",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.739",
                "llava": "0.594",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.590",
                "llava": "0.462",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.591",
                "llava": "0.444",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00490": {
        "id": "490",
        "prompt": "A hotel with no guests checking in.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.785",
                "llava": "0.635",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.726",
                "llava": "0.636",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.765",
                "llava": "0.610",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.509",
                "llava": "0.338",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00269": {
        "id": "00269",
        "prompt": "A bakery where every shelf is filled with a variety of bread and pastries.",
        "prompt in Chinese": "\u4e00\u4e2a\u9762\u5305\u5e97\uff0c\u6bcf\u4e2a\u67b6\u5b50\u4e0a\u90fd\u6446\u6ee1\u4e86\u5404\u5f0f\u5404\u6837\u7684\u9762\u5305\u548c\u7cd5\u70b9.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.846",
                "llava": "0.780",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.971",
                "llava": "0.825",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.953",
                "llava": "0.788",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.928",
                "llava": "0.739",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00009": {
        "id": "00009",
        "prompt": "A ghostly ship sailing on a fog-shrouded, moonlit sea.",
        "prompt in Chinese": "\u4e00\u8258\u5e7d\u7075\u8239\u5728\u6d53\u96fe\u7b3c\u7f69\u3001\u6708\u591c\u7684\u6d77\u4e0a\u822a\u884c\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.918",
                "llava": "0.737",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.927",
                "llava": "0.735",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.932",
                "llava": "0.730",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.725",
                "llava": "0.735",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00374": {
        "id": "374",
        "prompt": "One circular window shines brightly with light, another rectangular one is dark.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.827",
                "llava": "0.592",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.783",
                "llava": "0.553",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.787",
                "llava": "0.609",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.356",
                "llava": "0.434",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00301": {
        "id": "301",
        "prompt": "A woman with red lipstick and a polka dot dress.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.986",
                "llava": "0.810",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.987",
                "llava": "0.795",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.763",
                "llava": "0.660",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.810",
                "llava": "0.717",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00047": {
        "id": "00047",
        "prompt": "A garden path lined with glowing stones under a twilight sky.",
        "prompt in Chinese": "\u9ec4\u660f\u5929\u7a7a\u4e0b\uff0c\u4e00\u6761\u56ed\u5f84\u4e24\u65c1\u70b9\u7f00\u7740\u53d1\u5149\u7684\u77f3\u5934\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.954",
                "llava": "0.804",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.961",
                "llava": "0.776",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.944",
                "llava": "0.772",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.593",
                "llava": "0.540",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00049": {
        "id": "00049",
        "prompt": "A cavern lit by shafts of light revealing hidden underground pools.",
        "prompt in Chinese": "\u5149\u675f\u7167\u4eae\u7684\u6d1e\u7a74\u5185\u63ed\u793a\u4e86\u9690\u85cf\u7684\u5730\u4e0b\u6c34\u6c60\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.948",
                "llava": "0.777",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.956",
                "llava": "0.810",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.623",
                "llava": "0.649",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.532",
                "llava": "0.265",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00332": {
        "id": "332",
        "prompt": "A mountain biker leaping over a log on a forest trail.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.526",
                "llava": "0.518",
                "human": "4.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.980",
                "llava": "0.696",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.856",
                "llava": "0.729",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.595",
                "llava": "0.458",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00245": {
        "id": "00245",
        "prompt": "In a magnificent castle, a red dragon sits and a green dragon flies.",
        "prompt in Chinese": "\u5728\u4e00\u4e2a\u5b8f\u4f1f\u7684\u57ce\u5821\u91cc\uff0c\u4e00\u6761\u7ea2\u9f99\u5750\u7740\uff0c\u4e00\u6761\u7eff\u9f99\u5728\u98de\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.365",
                "llava": "0.336",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.667",
                "llava": "0.508",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.825",
                "llava": "0.540",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.582",
                "llava": "0.501",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00226": {
        "id": "00226",
        "prompt": "A garden gate with 'Welcome Friends' painted on a hanging wooden plaque, surrounded by blooming flowers.",
        "prompt in Chinese": "\u4e00\u4e2a\u82b1\u56ed\u5927\u95e8\uff0c\u6302\u7740\u4e00\u5757\u5199\u7740'Welcome Friends' \u7684\u6728\u8d28\u62db\u724c\uff0c\u5468\u56f4\u73af\u7ed5\u7740\u76db\u5f00\u7684\u82b1\u6735\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.579",
                "llava": "0.490",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.987",
                "llava": "0.802",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.821",
                "llava": "0.579",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.814",
                "llava": "0.777",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00081": {
        "id": "00081",
        "prompt": "A snowy owl perched to the right on a frost-covered branch.",
        "prompt in Chinese": "\u4e00\u53ea\u96ea\u767d\u7684\u732b\u5934\u9e70\u6816\u606f\u5728\u53f3\u4fa7\u7ed3\u971c\u7684\u6811\u679d\u4e0a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.974",
                "llava": "0.827",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.919",
                "llava": "0.832",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.947",
                "llava": "0.809",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.879",
                "llava": "0.702",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00366": {
        "id": "366",
        "prompt": "In the pond, two ducks swim near each other: the larger one has a bright green head, while the smaller one is all brown.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.869",
                "llava": "0.772",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.778",
                "llava": "0.691",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.916",
                "llava": "0.743",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.726",
                "llava": "0.535",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00295": {
        "id": "295",
        "prompt": "There is a watering can and a flowerpot on the table, the watering can is bigger than the flowerpot.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.904",
                "llava": "0.696",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.786",
                "llava": "0.751",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.884",
                "llava": "0.698",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.756",
                "llava": "0.639",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00084": {
        "id": "00084",
        "prompt": "A crystal-clear lake reflecting a mountainous landscape.",
        "prompt in Chinese": "\u4e00\u7247\u6e05\u6f88\u7684\u6e56\u9762\u53cd\u5c04\u51fa\u5c71\u5ce6\u7684\u666f\u8c61\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.959",
                "llava": "0.833",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.970",
                "llava": "0.848",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.976",
                "llava": "0.859",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.918",
                "llava": "0.738",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00400": {
        "id": "400",
        "prompt": "A pair of yellow rubber boots standing at the doorstep, with a pair of green gardening gloves draped over them.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.820",
                "llava": "0.625",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.754",
                "llava": "0.711",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.912",
                "llava": "0.693",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.851",
                "llava": "0.763",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00158": {
        "id": "00158",
        "prompt": "One ecstatic painter in front of four confused muses.",
        "prompt in Chinese": "\u4e00\u4e2a\u6b23\u559c\u82e5\u72c2\u7684\u753b\u5bb6\u9762\u5bf9\u56db\u4e2a\u56f0\u60d1\u7684\u7f2a\u65af\u5973\u795e\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.198",
                "llava": "0.317",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.524",
                "llava": "0.362",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.736",
                "llava": "0.503",
                "human": "1.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.569",
                "llava": "0.301",
                "human": "1.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00386": {
        "id": "386",
        "prompt": "A big green apple next to a small red apple on a kitchen counter.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.849",
                "llava": "0.707",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.921",
                "llava": "0.801",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.934",
                "llava": "0.784",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.761",
                "llava": "0.632",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00456": {
        "id": "456",
        "prompt": "A playground with no children playing.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.875",
                "llava": "0.668",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.925",
                "llava": "0.650",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.096",
                "llava": "0.233",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.902",
                "llava": "0.706",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00053": {
        "id": "00053",
        "prompt": "A village covered in snow, illuminated by the northern lights.",
        "prompt in Chinese": "\u4e00\u4e2a\u88ab\u96ea\u8986\u76d6\u7684\u6751\u5e84\uff0c\u5728\u5317\u6781\u5149\u7684\u7167\u8000\u4e0b\u53d1\u4eae\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.845",
                "llava": "0.772",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.979",
                "llava": "0.790",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.916",
                "llava": "0.752",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.698",
                "llava": "0.586",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00062": {
        "id": "00062",
        "prompt": "A baker with a cherry pin on a polka dot apron.",
        "prompt in Chinese": "\u4e00\u4f4d\u5728\u5706\u70b9\u56f4\u88d9\u4e0a\u522b\u7740\u6a31\u6843\u522b\u9488\u7684\u9762\u5305\u5e08\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.914",
                "llava": "0.640",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.582",
                "llava": "0.440",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.738",
                "llava": "0.542",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.245",
                "llava": "0.321",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00187": {
        "id": "00187",
        "prompt": "A smiling girl with short hair and no glasses.",
        "prompt in Chinese": "\u4e00\u4e2a\u77ed\u53d1\u4e0d\u6234\u773c\u955c\u7684\u5fae\u7b11\u5973\u5b69\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.844",
                "llava": "0.636",
                "human": "4.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.861",
                "llava": "0.818",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.889",
                "llava": "0.752",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.938",
                "llava": "0.794",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00082": {
        "id": "00082",
        "prompt": "A vintage clock on a mantelpiece leaning slightly to the left.",
        "prompt in Chinese": "\u58c1\u7089\u67b6\u4e0a\u7684\u4e00\u53ea\u53e4\u8463\u949f\u5fae\u5fae\u5411\u5de6\u503e\u659c\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.868",
                "llava": "0.633",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.587",
                "llava": "0.494",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.843",
                "llava": "0.667",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.605",
                "llava": "0.578",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00135": {
        "id": "00135",
        "prompt": "A window consists of two panes of glass, the left one is broken but the right one is intact.",
        "prompt in Chinese": "\u4e00\u6247\u7a97\u6237\u7531\u4e24\u5757\u73bb\u7483\u7ec4\u6210\uff0c\u5de6\u8fb9\u7684\u73bb\u7483\u788e\u4e86\uff0c\u53f3\u8fb9\u7684\u5374\u5b8c\u597d\u65e0\u635f\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.712",
                "llava": "0.352",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.496",
                "llava": "0.448",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.095",
                "llava": "0.289",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.838",
                "llava": "0.525",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00303": {
        "id": "303",
        "prompt": "A man in a lab coat examining a beaker of colorful liquid.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.984",
                "llava": "0.839",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.985",
                "llava": "0.856",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.976",
                "llava": "0.795",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.932",
                "llava": "0.861",
                "human": "4.00",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "4"
            }
        }
    },
    "00408": {
        "id": "408",
        "prompt": "An antique bookshop with aisles filled with books.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.910",
                "llava": "0.814",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.932",
                "llava": "0.773",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.820",
                "llava": "0.724",
                "human": "5.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.939",
                "llava": "0.776",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00473": {
        "id": "473",
        "prompt": "Two birds in the sky; the one on the left is flying, but the one on the right is not.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.339",
                "llava": "0.258",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.728",
                "llava": "0.610",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.574",
                "llava": "0.393",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.429",
                "llava": "0.296",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00312": {
        "id": "312",
        "prompt": "A hiker reaching the summit of a mountain with arms raised.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.268",
                "llava": "0.438",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.966",
                "llava": "0.714",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.950",
                "llava": "0.671",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.658",
                "llava": "0.507",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00319": {
        "id": "319",
        "prompt": "A violinist playing in a candlelit room.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.976",
                "llava": "0.863",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.983",
                "llava": "0.818",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.982",
                "llava": "0.872",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.936",
                "llava": "0.813",
                "human": "5.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00427": {
        "id": "427",
        "prompt": "In a field of flowers, every bloom is yellow, save for one that is blue.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.920",
                "llava": "0.613",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.587",
                "llava": "0.506",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.655",
                "llava": "0.634",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.461",
                "llava": "0.361",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00122": {
        "id": "00122",
        "prompt": "Children are swinging on the swings while their parents watch from nearby, and a puppy frolics around them.",
        "prompt in Chinese": "\u5b69\u5b50\u4eec\u5728\u79cb\u5343\u4e0a\u8361\u79cb\u5343\uff0c\u4ed6\u4eec\u7684\u7236\u6bcd\u5728\u65c1\u8fb9\u89c2\u770b\uff0c\u4e00\u53ea\u5c0f\u72d7\u5728\u4ed6\u4eec\u8eab\u8fb9\u5b09\u620f\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.164",
                "llava": "0.251",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.519",
                "llava": "0.316",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.895",
                "llava": "0.615",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.358",
                "llava": "0.245",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00276": {
        "id": "00276",
        "prompt": "A young lady wearing a T-shirt puts her hand on a puppy's head.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.788",
                "llava": "0.690",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.914",
                "llava": "0.730",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.726",
                "llava": "0.618",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.914",
                "llava": "0.796",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            }
        }
    },
    "00281": {
        "id": "00281",
        "prompt": "A dog chasing a cat.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.523",
                "llava": "0.237",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.881",
                "llava": "0.691",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.311",
                "llava": "0.224",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.144",
                "llava": "0.211",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00154": {
        "id": "00154",
        "prompt": "Four nervous mice and one confident cat.",
        "prompt in Chinese": "\u56db\u53ea\u7d27\u5f20\u7684\u8001\u9f20\u548c\u4e00\u53ea\u81ea\u4fe1\u7684\u732b\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.144",
                "llava": "0.167",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.633",
                "llava": "0.252",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.391",
                "llava": "0.241",
                "human": "1.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.226",
                "llava": "0.241",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00291": {
        "id": "00291",
        "prompt": "A man is pushing a box full of flowers on the floor.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.815",
                "llava": "0.645",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.843",
                "llava": "0.730",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.786",
                "llava": "0.617",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.738",
                "llava": "0.699",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00302": {
        "id": "302",
        "prompt": "An artist in a paint-splattered apron holding a palette.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.902",
                "llava": "0.732",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.804",
                "llava": "0.811",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.946",
                "llava": "0.769",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.926",
                "llava": "0.776",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00504": {
        "id": "504",
        "prompt": "A vintage car show with more convertibles than sedans.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.836",
                "llava": "0.708",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.725",
                "llava": "0.672",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.865",
                "llava": "0.653",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.782",
                "llava": "0.686",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00140": {
        "id": "00140",
        "prompt": "Five cylindrical mugs beside two rectangular napkins.",
        "prompt in Chinese": "\u4e94\u4e2a\u5706\u67f1\u5f62\u9a6c\u514b\u676f\uff0c\u65c1\u8fb9\u662f\u4e24\u5757\u957f\u65b9\u5f62\u9910\u5dfe\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.557",
                "llava": "0.332",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.799",
                "llava": "0.466",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.564",
                "llava": "0.338",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.254",
                "llava": "0.553",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00059": {
        "id": "00059",
        "prompt": "A lone lighthouse standing guard on a rocky coastline.",
        "prompt in Chinese": "\u4e00\u5ea7\u72ec\u7acb\u7684\u706f\u5854\u5b88\u536b\u7740\u5ca9\u77f3\u6d77\u5cb8\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.942",
                "llava": "0.810",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.937",
                "llava": "0.812",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.863",
                "llava": "0.794",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.936",
                "llava": "0.780",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00171": {
        "id": "00171",
        "prompt": "The smiling child gives an apple to the frowning child.",
        "prompt in Chinese": "\u5fae\u7b11\u7684\u5b69\u5b50\u7ed9\u76b1\u7709\u7684\u5b69\u5b50\u4e00\u4e2a\u82f9\u679c\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.178",
                "llava": "0.194",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.463",
                "llava": "0.442",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.811",
                "llava": "0.429",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.412",
                "llava": "0.318",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00117": {
        "id": "00117",
        "prompt": "In a peaceful pond, there are more fish in the water than frogs on the lotus leaves.",
        "prompt in Chinese": "\u5728\u4e00\u4e2a\u5b81\u9759\u7684\u6c60\u5858\u4e2d\uff0c\u6c34\u4e2d\u7684\u9c7c\u6bd4\u8377\u53f6\u4e0a\u7684\u9752\u86d9\u591a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.520",
                "llava": "0.441",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.415",
                "llava": "0.415",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.808",
                "llava": "0.550",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.520",
                "llava": "0.380",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00331": {
        "id": "331",
        "prompt": "A child making a sandcastle on a beach in a cloudy day.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.900",
                "llava": "0.634",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.802",
                "llava": "0.573",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.125",
                "llava": "0.409",
                "human": "4.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.820",
                "llava": "0.559",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00524": {
        "id": "524",
        "prompt": "Two shoes by the front door.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.804",
                "llava": "0.779",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.779",
                "llava": "0.756",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.953",
                "llava": "0.750",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.602",
                "llava": "0.381",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00526": {
        "id": "526",
        "prompt": "Four leaves on a branch.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.851",
                "llava": "0.670",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.723",
                "llava": "0.619",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.685",
                "llava": "0.657",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.719",
                "llava": "0.562",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00089": {
        "id": "00089",
        "prompt": "A star-filled sky over a desert campsite.",
        "prompt in Chinese": "\u6c99\u6f20\u8425\u5730\u4e0a\u65b9\u7684\u6ee1\u5929\u7e41\u661f\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.983",
                "llava": "0.852",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.984",
                "llava": "0.886",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.987",
                "llava": "0.847",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.845",
                "llava": "0.750",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00283": {
        "id": "00283",
        "prompt": "A group of children playing on the beach.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.956",
                "llava": "0.838",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.990",
                "llava": "0.828",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.871",
                "llava": "0.825",
                "human": "4.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.952",
                "llava": "0.820",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00344": {
        "id": "344",
        "prompt": "Kids race their bikes down the hill as their friends cheer from the sidelines, and a kite flutters in the breeze above them.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.661",
                "llava": "0.540",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.679",
                "llava": "0.524",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.629",
                "llava": "0.629",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.734",
                "llava": "0.552",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            }
        }
    },
    "00336": {
        "id": "336",
        "prompt": "A gymnast performing a routine on the balance beam.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.735",
                "llava": "0.680",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.901",
                "llava": "0.754",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.945",
                "llava": "0.860",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.961",
                "llava": "0.792",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            }
        }
    },
    "00381": {
        "id": "381",
        "prompt": "A butterfly with bright wings flits from flower to flower, another rests on a leaf, wings folded.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.902",
                "llava": "0.633",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.605",
                "llava": "0.533",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.623",
                "llava": "0.549",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.630",
                "llava": "0.594",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00423": {
        "id": "423",
        "prompt": "Every tree in the forest is green, except for one that is red.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.742",
                "llava": "0.538",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.279",
                "llava": "0.274",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.701",
                "llava": "0.491",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.192",
                "llava": "0.160",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00088": {
        "id": "00088",
        "prompt": "A narrow alleyway illuminated by strings of fairy lights.",
        "prompt in Chinese": "\u4e00\u6761\u72ed\u7a84\u7684\u5df7\u9053\u88ab\u4e32\u4e32\u4ed9\u706f\u7167\u4eae\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.973",
                "llava": "0.828",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.980",
                "llava": "0.867",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.974",
                "llava": "0.876",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.954",
                "llava": "0.863",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00467": {
        "id": "467",
        "prompt": "A snowy landscape with a cabin, but no smoke from the chimney.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.797",
                "llava": "0.719",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.727",
                "llava": "0.684",
                "human": "5.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.858",
                "llava": "0.679",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.806",
                "llava": "0.662",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00522": {
        "id": "522",
        "prompt": "Five stars in the night sky.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.570",
                "llava": "0.525",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.613",
                "llava": "0.415",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.544",
                "llava": "0.364",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.464",
                "llava": "0.446",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00383": {
        "id": "383",
        "prompt": "A silver spoon lies to the left of a golden fork on a wooden table.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.843",
                "llava": "0.716",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.511",
                "llava": "0.607",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.761",
                "llava": "0.348",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.200",
                "llava": "0.206",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00268": {
        "id": "00268",
        "prompt": "A traditional potter's workshop, where every shelf holds rows of terracotta pots, each imprinted with intricate designs.",
        "prompt in Chinese": "\u4e00\u4e2a\u4f20\u7edf\u7684\u9676\u5668\u5de5\u4f5c\u5ba4\uff0c\u6bcf\u4e2a\u67b6\u5b50\u4e0a\u90fd\u6446\u6ee1\u4e86\u6392\u6392\u6574\u9f50\u7684\u9676\u7f50\uff0c\u6bcf\u4e2a\u9676\u7f50\u4e0a\u90fd\u5370\u6709\u590d\u6742\u7684\u56fe\u6848\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.879",
                "llava": "0.827",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.793",
                "llava": "0.732",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.813",
                "llava": "0.760",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.703",
                "llava": "0.441",
                "human": "4.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00521": {
        "id": "521",
        "prompt": "Four pencils in a cup.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.637",
                "llava": "0.631",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.902",
                "llava": "0.620",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.248",
                "llava": "0.326",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.887",
                "llava": "0.671",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            }
        }
    },
    "00322": {
        "id": "322",
        "prompt": "A teacher standing in front of a world map in a classroom.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.671",
                "llava": "0.790",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.826",
                "llava": "0.551",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.964",
                "llava": "0.842",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.690",
                "llava": "0.549",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00102": {
        "id": "00102",
        "prompt": "A little girl tuning a guitar before a concert in a dimly lit venue.",
        "prompt in Chinese": "\u4e00\u4e2a\u5c0f\u5973\u5b69\u5728\u660f\u6697\u7684\u573a\u5730\u4e2d\u8c03\u97f3\u5409\u4ed6\uff0c\u51c6\u5907\u97f3\u4e50\u4f1a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.670",
                "llava": "0.620",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.743",
                "llava": "0.641",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.719",
                "llava": "0.623",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.757",
                "llava": "0.588",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00133": {
        "id": "00133",
        "prompt": "The sun sets on the left while the moon rises on the right.",
        "prompt in Chinese": "\u592a\u9633\u5728\u5de6\u8fb9\u843d\u4e0b\uff0c\u6708\u4eae\u5728\u53f3\u8fb9\u5347\u8d77\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.567",
                "llava": "0.580",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.807",
                "llava": "0.532",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.286",
                "llava": "0.445",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.797",
                "llava": "0.483",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00067": {
        "id": "00067",
        "prompt": "A pirate with a skull earring on a treasure island.",
        "prompt in Chinese": "\u5728\u5b9d\u85cf\u5c9b\u4e0a,\u6234\u7740\u9ab7\u9ac5\u8033\u73af\u7684\u6d77\u76d7\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.624",
                "llava": "0.736",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.608",
                "llava": "0.449",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.853",
                "llava": "0.627",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.604",
                "llava": "0.461",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00341": {
        "id": "341",
        "prompt": "A knight in shining armor jousting at a medieval fair.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.517",
                "llava": "0.619",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.920",
                "llava": "0.716",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.698",
                "llava": "0.672",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.873",
                "llava": "0.586",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00220": {
        "id": "00220",
        "prompt": "A busy urban intersection, a traffic sign at the roadside displaying 'Speed Limit 30 mph'.",
        "prompt in Chinese": "\u4e00\u4e2a\u7e41\u5fd9\u7684\u57ce\u5e02\u5341\u5b57\u8def\u53e3\uff0c\u8def\u8fb9\u7684\u4ea4\u901a\u6807\u5fd7\u663e\u793a'Speed Limit 30 mph'\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.922",
                "llava": "0.724",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.730",
                "llava": "0.583",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.640",
                "llava": "0.616",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.753",
                "llava": "0.709",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            }
        }
    },
    "00224": {
        "id": "00224",
        "prompt": "A bustling city street, a neon 'Open 24 Hours' sign glowing above a small diner.",
        "prompt in Chinese": "\u4e00\u4e2a\u7e41\u5fd9\u7684\u57ce\u5e02\u8857\u9053\uff0c\u4e00\u5bb6\u5c0f\u9910\u9986\u4e0a\u65b9\u95ea\u70c1\u7740'Open 24 Hours'\u7684\u9713\u8679\u706f\u724c\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.771",
                "llava": "0.703",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.947",
                "llava": "0.791",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.864",
                "llava": "0.753",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.819",
                "llava": "0.743",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00046": {
        "id": "00046",
        "prompt": "An old lantern swaying from a tree branch in a foggy forest.",
        "prompt in Chinese": "\u4e00\u4e2a\u65e7\u706f\u7b3c\u5728\u96fe\u8499\u8499\u7684\u68ee\u6797\u91cc\u7684\u6811\u679d\u4e0a\u6447\u6643\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.935",
                "llava": "0.672",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.971",
                "llava": "0.673",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.275",
                "llava": "0.696",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.962",
                "llava": "0.695",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00113": {
        "id": "00113",
        "prompt": "A workspace with more computers than computer mice.",
        "prompt in Chinese": "\u4e00\u4e2a\u5de5\u4f5c\u7a7a\u95f4\u91cc\uff0c\u7535\u8111\u6bd4\u9f20\u6807\u591a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.742",
                "llava": "0.598",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.746",
                "llava": "0.616",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.688",
                "llava": "0.632",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.714",
                "llava": "0.640",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00293": {
        "id": "293",
        "prompt": "One cat is sleeping on the table and the other is playing under the table.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.161",
                "llava": "0.140",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.240",
                "llava": "0.136",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.365",
                "llava": "0.294",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.459",
                "llava": "0.254",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00176": {
        "id": "00176",
        "prompt": "The two lay in bed, the long-haired one asleep, the short-haired one still awake.",
        "prompt in Chinese": "\u4e24\u4e2a\u4eba\u8eba\u5728\u5e8a\u4e0a\uff0c\u957f\u53d1\u7684\u4e00\u4e2a\u7761\u7740\u4e86\uff0c\u77ed\u53d1\u7684\u4e00\u4e2a\u8fd8\u9192\u7740\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.811",
                "llava": "0.595",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.840",
                "llava": "0.601",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.431",
                "llava": "0.454",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.657",
                "llava": "0.690",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "3"
            }
        }
    },
    "00493": {
        "id": "493",
        "prompt": "A bustling street with more bicycles than cars parked along the sidewalk.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.738",
                "llava": "0.699",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.826",
                "llava": "0.744",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.809",
                "llava": "0.691",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.733",
                "llava": "0.574",
                "human": "4.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00041": {
        "id": "00041",
        "prompt": "A teapot steaming gently on a rustic kitchen table.",
        "prompt in Chinese": "\u4e00\u58f6\u8336\u58f6\u5728\u4e61\u6751\u53a8\u623f\u7684\u684c\u5b50\u4e0a\u8f7b\u8f7b\u5730\u5192\u7740\u70ed\u6c14\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.598",
                "llava": "0.694",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.967",
                "llava": "0.772",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.956",
                "llava": "0.791",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.943",
                "llava": "0.810",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "3"
            }
        }
    },
    "00134": {
        "id": "00134",
        "prompt": "Two lampshades flank a bed: the one on the left is tilted, while the one on the right stands straight.",
        "prompt in Chinese": "\u4e24\u4e2a\u706f\u7f69\u77d7\u7acb\u5728\u5e8a\u7684\u4e24\u4fa7\uff1a\u5de6\u8fb9\u7684\u503e\u659c\uff0c\u800c\u53f3\u8fb9\u7684\u76f4\u7acb\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.887",
                "llava": "0.640",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.918",
                "llava": "0.734",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.912",
                "llava": "0.735",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.128",
                "llava": "0.342",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00282": {
        "id": "00282",
        "prompt": "A group of children playing in the garden.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.099",
                "llava": "0.184",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.983",
                "llava": "0.816",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.978",
                "llava": "0.841",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.967",
                "llava": "0.794",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00428": {
        "id": "428",
        "prompt": "In a line of dominoes, each one stands upright, except for one that has fallen over.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.779",
                "llava": "0.699",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.769",
                "llava": "0.661",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.793",
                "llava": "0.710",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.760",
                "llava": "0.642",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00096": {
        "id": "00096",
        "prompt": "A painter delicately brushing color onto a canvas in a bright, airy studio.",
        "prompt in Chinese": "\u4e00\u4f4d\u753b\u5bb6\u5728\u660e\u4eae\u3001\u901a\u98ce\u7684\u5de5\u4f5c\u5ba4\u5185\u7ec6\u81f4\u5730\u7ed9\u753b\u5e03\u4e0a\u8272\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.685",
                "llava": "0.580",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.927",
                "llava": "0.682",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.383",
                "llava": "0.595",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.813",
                "llava": "0.569",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00165": {
        "id": "00165",
        "prompt": "Some oranges on the left are moldy while an orange on the right is fresh.",
        "prompt in Chinese": "\u5de6\u8fb9\u7684\u4e00\u4e9b\u6a59\u5b50\u53d1\u9709\u4e86\uff0c\u800c\u53f3\u8fb9\u7684\u4e00\u4e2a\u6a59\u5b50\u662f\u65b0\u9c9c\u7684\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.602",
                "llava": "0.406",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.258",
                "llava": "0.327",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.625",
                "llava": "0.510",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.784",
                "llava": "0.652",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00027": {
        "id": "00027",
        "prompt": "A girl dabs paint on a mural.",
        "prompt in Chinese": "\u4e00\u4e2a\u5973\u5b69\u5728\u58c1\u753b\u4e0a\u6d82\u989c\u6599\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.959",
                "llava": "0.811",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.639",
                "llava": "0.656",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.877",
                "llava": "0.806",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.781",
                "llava": "0.609",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00118": {
        "id": "00118",
        "prompt": "City view, the tower on the left is taller than the one on the right.",
        "prompt in Chinese": "\u57ce\u5e02\u666f\u89c2\uff0c\u5de6\u8fb9\u7684\u5854\u697c\u6bd4\u53f3\u8fb9\u7684\u9ad8\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.804",
                "llava": "0.739",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.827",
                "llava": "0.704",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.787",
                "llava": "0.710",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.801",
                "llava": "0.693",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00478": {
        "id": "478",
        "prompt": "A basket full of apples, but no oranges.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.902",
                "llava": "0.812",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.841",
                "llava": "0.812",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.909",
                "llava": "0.810",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.928",
                "llava": "0.773",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00186": {
        "id": "00186",
        "prompt": "A tailless, not black, cat is sitting.",
        "prompt in Chinese": "\u4e00\u53ea\u6ca1\u6709\u5c3e\u5df4\u7684\u4e14\u975e\u9ed1\u8272\u7684\u732b\u6b63\u5750\u7740\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.276",
                "llava": "0.231",
                "human": "1.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.180",
                "llava": "0.116",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.685",
                "llava": "0.393",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.230",
                "llava": "0.259",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00412": {
        "id": "412",
        "prompt": "At the party, a pineapple is flanked by beers on each side.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.907",
                "llava": "0.760",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.888",
                "llava": "0.799",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.949",
                "llava": "0.814",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.689",
                "llava": "0.689",
                "human": "5.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00085": {
        "id": "00085",
        "prompt": "A row of colorful townhouses on a sunny street.",
        "prompt in Chinese": "\u9633\u5149\u4e0b\u4e00\u6392\u8272\u5f69\u7f24\u7eb7\u7684\u57ce\u9547\u623f\u5c4b\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.956",
                "llava": "0.784",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.874",
                "llava": "0.880",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.974",
                "llava": "0.885",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.870",
                "llava": "0.755",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00200": {
        "id": "00200",
        "prompt": "Four elephants, no giraffes.",
        "prompt in Chinese": "\u56db\u53ea\u5927\u8c61\uff0c\u6ca1\u6709\u957f\u9888\u9e7f\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.480",
                "llava": "0.589",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.920",
                "llava": "0.707",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.870",
                "llava": "0.677",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.809",
                "llava": "0.737",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            }
        }
    },
    "00086": {
        "id": "00086",
        "prompt": "An ancient scroll unrolled on a wooden desk.",
        "prompt in Chinese": "\u4e00\u5377\u53e4\u8001\u7684\u5377\u8f74\u5c55\u5f00\u5728\u6728\u5236\u4e66\u684c\u4e0a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.923",
                "llava": "0.786",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.927",
                "llava": "0.817",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.925",
                "llava": "0.818",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.881",
                "llava": "0.867",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00051": {
        "id": "00051",
        "prompt": "Shelves carved from tree branches in a mystical library.",
        "prompt in Chinese": "\u4e00\u4e2a\u795e\u79d8\u56fe\u4e66\u9986\u91cc\u7528\u6811\u679d\u96d5\u523b\u7684\u4e66\u67b6\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.606",
                "llava": "0.634",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.644",
                "llava": "0.619",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.874",
                "llava": "0.709",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.930",
                "llava": "0.736",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00093": {
        "id": "00093",
        "prompt": "A vibrant mural depicts a giant parrot, urban apartment buildings serving as its canvas.",
        "prompt in Chinese": "\u4e00\u5e45\u751f\u52a8\u7684\u58c1\u753b\u63cf\u7ed8\u4e86\u4e00\u53ea\u5de8\u5927\u7684\u9e66\u9e49\uff0c\u57ce\u5e02\u7684\u516c\u5bd3\u697c\u4f5c\u4e3a\u5176\u753b\u5e03\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.566",
                "llava": "0.609",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.973",
                "llava": "0.862",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.966",
                "llava": "0.838",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.953",
                "llava": "0.803",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00070": {
        "id": "00070",
        "prompt": "A cheerleader with a star badge at a sports field.",
        "prompt in Chinese": "\u4e00\u4f4d\u5728\u8fd0\u52a8\u573a\u4e0a\u4f69\u6234\u661f\u5f62\u5fbd\u7ae0\u7684\u5566\u5566\u961f\u957f\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.933",
                "llava": "0.846",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.977",
                "llava": "0.861",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.953",
                "llava": "0.887",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.952",
                "llava": "0.877",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00008": {
        "id": "00008",
        "prompt": "A phoenix soaring above a city, aglow with golden flames.",
        "prompt in Chinese": "\u4e00\u53ea\u51e4\u51f0\u5728\u57ce\u5e02\u4e0a\u7a7a\u98de\u7fd4\uff0c\u8eab\u62ab\u91d1\u8272\u706b\u7130\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.879",
                "llava": "0.622",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.605",
                "llava": "0.632",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.795",
                "llava": "0.761",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.442",
                "llava": "0.365",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00074": {
        "id": "00074",
        "prompt": "A cheerful dog with a frisbee in its mouth on the right, chasing a rolling ball on the left.",
        "prompt in Chinese": "\u53f3\u8fb9\u4e00\u53ea\u5634\u91cc\u53fc\u7740\u98de\u76d8\u7684\u5feb\u4e50\u7684\u72d7\uff0c\u6b63\u5728\u8ffd\u8d76\u5de6\u8fb9\u6eda\u52a8\u7684\u7403\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.749",
                "llava": "0.406",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.357",
                "llava": "0.271",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.310",
                "llava": "0.387",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.261",
                "llava": "0.279",
                "human": "4.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00107": {
        "id": "00107",
        "prompt": "On the party table, chocolate chip cookies outnumber the frosted cupcakes.",
        "prompt in Chinese": "\u6d3e\u5bf9\u684c\u4e0a\uff0c\u5de7\u514b\u529b\u997c\u5e72\u7684\u6570\u91cf\u8d85\u8fc7\u4e86\u7eb8\u676f\u86cb\u7cd5\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.708",
                "llava": "0.505",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.613",
                "llava": "0.558",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.239",
                "llava": "0.408",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.717",
                "llava": "0.472",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00040": {
        "id": "00040",
        "prompt": "A red bicycle parked against a brightly painted wall.",
        "prompt in Chinese": "\u4e00\u8f86\u7ea2\u8272\u81ea\u884c\u8f66\u9760\u5728\u4e00\u5835\u9c9c\u8273\u7684\u5899\u58c1\u4e0a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.984",
                "llava": "0.812",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.988",
                "llava": "0.895",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.467",
                "llava": "0.517",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.881",
                "llava": "0.763",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00388": {
        "id": "388",
        "prompt": "A yellow school bus in front of a red fire engine at a community event.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.106",
                "llava": "0.179",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.747",
                "llava": "0.551",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.604",
                "llava": "0.393",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.363",
                "llava": "0.365",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00278": {
        "id": "00278",
        "prompt": "A young woman wearing a red T-shirt.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.978",
                "llava": "0.883",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.962",
                "llava": "0.919",
                "human": "5.00",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.975",
                "llava": "0.901",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.977",
                "llava": "0.857",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00094": {
        "id": "00094",
        "prompt": "A whimsical garden features glowing flowers, luminescent stones lining the pathway beneath.",
        "prompt in Chinese": "\u4e00\u4e2a\u5f02\u60f3\u5929\u5f00\u7684\u82b1\u56ed\u91cc\uff0c\u591c\u5149\u82b1\u6735\u7efd\u653e\uff0c\u8def\u5f84\u4e0b\u94fa\u6ee1\u4e86\u53d1\u5149\u7684\u77f3\u5934\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.957",
                "llava": "0.845",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.687",
                "llava": "0.756",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.875",
                "llava": "0.704",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.903",
                "llava": "0.786",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00056": {
        "id": "00056",
        "prompt": "A small dog dozing in a patch of sunlight.",
        "prompt in Chinese": "\u4e00\u53ea\u5c0f\u72d7\u5728\u4e00\u7247\u9633\u5149\u4e0b\u6253\u76f9\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.961",
                "llava": "0.804",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.878",
                "llava": "0.834",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.871",
                "llava": "0.786",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.606",
                "llava": "0.565",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00498": {
        "id": "498",
        "prompt": "A classroom with more chairs than students.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.845",
                "llava": "0.712",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.837",
                "llava": "0.771",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.843",
                "llava": "0.731",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.787",
                "llava": "0.773",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "3"
            }
        }
    },
    "00173": {
        "id": "00173",
        "prompt": "In the supermarket, a man with glasses pays a man without glasses.",
        "prompt in Chinese": "\u5728\u8d85\u5e02\u91cc\uff0c\u4e00\u4e2a\u6234\u773c\u955c\u7684\u7537\u4eba\u4ed8\u94b1\u7ed9\u4e00\u4e2a\u4e0d\u6234\u773c\u955c\u7684\u7537\u4eba\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.252",
                "llava": "0.291",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.297",
                "llava": "0.196",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.607",
                "llava": "0.481",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.330",
                "llava": "0.196",
                "human": "1.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00168": {
        "id": "00168",
        "prompt": "An old owl watches as a young owl tries its first flight.",
        "prompt in Chinese": "\u4e00\u53ea\u8001\u732b\u5934\u9e70\u89c2\u5bdf\u7740\u4e00\u53ea\u5e74\u8f7b\u7684\u732b\u5934\u9e70\u5c1d\u8bd5\u7b2c\u4e00\u6b21\u98de\u884c\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.124",
                "llava": "0.122",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.211",
                "llava": "0.150",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.159",
                "llava": "0.188",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.475",
                "llava": "0.191",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00110": {
        "id": "00110",
        "prompt": "A larger person in yellow clothing and a smaller person in a different color.",
        "prompt in Chinese": "\u4e00\u4e2a\u7a7f\u9ec4\u8272\u8863\u670d\u7684\u5927\u4e2a\u5b50\u548c\u4e00\u4e2a\u7a7f\u4e0d\u540c\u989c\u8272\u8863\u670d\u7684\u5c0f\u4e2a\u5b50\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.624",
                "llava": "0.612",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.694",
                "llava": "0.632",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.441",
                "llava": "0.402",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.727",
                "llava": "0.529",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00119": {
        "id": "00119",
        "prompt": "The sun illuminates the garden, a shovel sticks in the soil, and gloves lay on the bench.",
        "prompt in Chinese": "\u9633\u5149\u7167\u4eae\u4e86\u82b1\u56ed\uff0c\u94f2\u5b50\u63d2\u5728\u571f\u91cc\uff0c\u624b\u5957\u653e\u5728\u957f\u6905\u4e0a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.712",
                "llava": "0.628",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.474",
                "llava": "0.504",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.787",
                "llava": "0.677",
                "human": "1.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.601",
                "llava": "0.460",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00055": {
        "id": "00055",
        "prompt": "An asteroid spaceport bustling with aliens and spacecraft.",
        "prompt in Chinese": "\u4e00\u4e2a\u7e41\u5fd9\u7684\u5c0f\u884c\u661f\u592a\u7a7a\u6e2f\uff0c\u5145\u6ee1\u5916\u661f\u4eba\u548c\u5b87\u5b99\u98de\u8239\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.568",
                "llava": "0.620",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.742",
                "llava": "0.622",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.821",
                "llava": "0.646",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.690",
                "llava": "0.631",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00116": {
        "id": "00116",
        "prompt": "A kitchen with a larger quantity of milk than juice.",
        "prompt in Chinese": "\u4e00\u4e2a\u53a8\u623f\u91cc\uff0c\u725b\u5976\u7684\u6570\u91cf\u6bd4\u679c\u6c41\u591a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.732",
                "llava": "0.739",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.578",
                "llava": "0.451",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.566",
                "llava": "0.559",
                "human": "1.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.366",
                "llava": "0.192",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00026": {
        "id": "00026",
        "prompt": "A young man tastes a simmering soup.",
        "prompt in Chinese": "\u4e00\u4f4d\u5e74\u8f7b\u4eba\u54c1\u5c1d\u6b63\u5728\u7096\u7684\u6c64\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.800",
                "llava": "0.765",
                "human": "4.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.851",
                "llava": "0.813",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.866",
                "llava": "0.826",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.866",
                "llava": "0.687",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00266": {
        "id": "00266",
        "prompt": "A group of people are gathered at a party, all sitting around a dining table.",
        "prompt in Chinese": "\u4e00\u7fa4\u4eba\u805a\u96c6\u5728\u6d3e\u5bf9\u4e0a\uff0c\u6240\u6709\u4eba\u90fd\u56f4\u5750\u5728\u9910\u684c\u5468\u56f4\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.118",
                "llava": "0.200",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.946",
                "llava": "0.845",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.923",
                "llava": "0.813",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.944",
                "llava": "0.781",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00125": {
        "id": "00125",
        "prompt": "A strange landscape, the ground on the left is covered with snow but the ground on the right is covered with green grass.",
        "prompt in Chinese": "\u4e00\u7247\u5947\u602a\u7684\u666f\u89c2\uff0c\u5de6\u8fb9\u7684\u5730\u9762\u8986\u76d6\u7740\u96ea\uff0c\u53f3\u8fb9\u7684\u5730\u4e0a\u5374\u957f\u6ee1\u4e86\u7eff\u8349\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.322",
                "llava": "0.451",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.873",
                "llava": "0.663",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.794",
                "llava": "0.707",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.537",
                "llava": "0.415",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00072": {
        "id": "00072",
        "prompt": "An astronaut with a flag patch drifting in space.",
        "prompt in Chinese": "\u4e00\u4f4d\u5728\u592a\u7a7a\u4e2d\u98d8\u8361\u7684\u5e26\u7740\u56fd\u65d7\u8865\u4e01\u7684\u5b87\u822a\u5458\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.651",
                "llava": "0.591",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.748",
                "llava": "0.726",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.864",
                "llava": "0.659",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.761",
                "llava": "0.758",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            }
        }
    },
    "00523": {
        "id": "523",
        "prompt": "One cat napping in the sun.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.933",
                "llava": "0.783",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.676",
                "llava": "0.757",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.888",
                "llava": "0.763",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.822",
                "llava": "0.728",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00250": {
        "id": "00250",
        "prompt": "A glowing ancient tree with five lanterns and surrounded by fireflies.",
        "prompt in Chinese": "\u4e00\u68f5\u53d1\u5149\u7684\u53e4\u6811\u4e0a\u6302\u7740\u4e94\u76cf\u706f\u7b3c\u5e76\u4e14\u88ab\u8424\u706b\u866b\u73af\u7ed5\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.553",
                "llava": "0.598",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.768",
                "llava": "0.666",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.763",
                "llava": "0.657",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.868",
                "llava": "0.747",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00286": {
        "id": "00286",
        "prompt": "A spotted dog, a cat and a bird on a round table.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.209",
                "llava": "0.319",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.089",
                "llava": "0.185",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.899",
                "llava": "0.671",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.571",
                "llava": "0.311",
                "human": "1.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00111": {
        "id": "00111",
        "prompt": "An animal with legs notably longer than a nearby person's.",
        "prompt in Chinese": "\u4e00\u53ea\u52a8\u7269\u7684\u817f\u660e\u663e\u6bd4\u9644\u8fd1\u7684\u4eba\u7684\u817f\u957f\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.891",
                "llava": "0.724",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.698",
                "llava": "0.669",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.920",
                "llava": "0.859",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.768",
                "llava": "0.744",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00380": {
        "id": "380",
        "prompt": "One squirrel gathers nuts quickly on the ground, another lazily stretches on a branch.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.247",
                "llava": "0.232",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.493",
                "llava": "0.421",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.236",
                "llava": "0.201",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.381",
                "llava": "0.222",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00060": {
        "id": "00060",
        "prompt": "A butterfly perched on a wildflower in a meadow.",
        "prompt in Chinese": "\u4e00\u53ea\u8774\u8776\u505c\u7559\u5728\u8349\u7538\u4e0a\u7684\u91ce\u82b1\u4e0a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.951",
                "llava": "0.844",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.861",
                "llava": "0.773",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.872",
                "llava": "0.821",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.830",
                "llava": "0.798",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00503": {
        "id": "503",
        "prompt": "An office with more desks than computers.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.694",
                "llava": "0.638",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.121",
                "llava": "0.152",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.673",
                "llava": "0.568",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.648",
                "llava": "0.503",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00442": {
        "id": "442",
        "prompt": "A bridge with no end, vanishing into the fog.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.827",
                "llava": "0.720",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.794",
                "llava": "0.768",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.817",
                "llava": "0.763",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.691",
                "llava": "0.605",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00294": {
        "id": "294",
        "prompt": "One cat is sleeping on the table and the other one is awake under the table.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.443",
                "llava": "0.443",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.460",
                "llava": "0.255",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.405",
                "llava": "0.255",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.227",
                "llava": "0.314",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "3"
            }
        }
    },
    "00315": {
        "id": "315",
        "prompt": "A barista creating latte art in a cozy cafe.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.905",
                "llava": "0.732",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.792",
                "llava": "0.685",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.699",
                "llava": "0.650",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.382",
                "llava": "0.443",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00106": {
        "id": "00106",
        "prompt": "The sky teems with more birds than the number of fish visible in the lake below.",
        "prompt in Chinese": "\u5929\u7a7a\u4e2d\u7684\u9e1f\u6bd4\u6e56\u91cc\u7684\u9c7c\u591a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.642",
                "llava": "0.565",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.823",
                "llava": "0.525",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.472",
                "llava": "0.495",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.291",
                "llava": "0.380",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00157": {
        "id": "00157",
        "prompt": "Five relaxed students but one overwhelmed teacher.",
        "prompt in Chinese": "\u4e94\u4e2a\u653e\u677e\u7684\u5b66\u751f\u548c\u4e00\u4e2a\u4e0d\u582a\u91cd\u8d1f\u7684\u8001\u5e08\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.350",
                "llava": "0.330",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.479",
                "llava": "0.334",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.285",
                "llava": "0.297",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.445",
                "llava": "0.335",
                "human": "1.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "4"
            }
        }
    },
    "00484": {
        "id": "484",
        "prompt": "A bridge over a river, but no cars crossing.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.827",
                "llava": "0.764",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.836",
                "llava": "0.731",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.810",
                "llava": "0.758",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.730",
                "llava": "0.698",
                "human": "5.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00458": {
        "id": "458",
        "prompt": "A river with no fish swimming.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.676",
                "llava": "0.611",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.642",
                "llava": "0.627",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.567",
                "llava": "0.641",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.826",
                "llava": "0.585",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00142": {
        "id": "00142",
        "prompt": "Six oval stones and four triangular sails.",
        "prompt in Chinese": "\u516d\u5757\u692d\u5706\u5f62\u7684\u77f3\u5934\u548c\u56db\u4e2a\u4e09\u89d2\u5f62\u7684\u5e06\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.308",
                "llava": "0.220",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.375",
                "llava": "0.206",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.406",
                "llava": "0.221",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.196",
                "llava": "0.395",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00492": {
        "id": "492",
        "prompt": "A beach scene where the sandcastle appears taller than the nearby cooler.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.800",
                "llava": "0.687",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.581",
                "llava": "0.591",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.611",
                "llava": "0.601",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.818",
                "llava": "0.692",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            }
        }
    },
    "00525": {
        "id": "525",
        "prompt": "Three cookies on a plate.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.944",
                "llava": "0.816",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.966",
                "llava": "0.724",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.890",
                "llava": "0.816",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.589",
                "llava": "0.796",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00356": {
        "id": "356",
        "prompt": "Inside the camp, a fire crackles, casting shadows on the tent walls, with backpacks and maps spread out.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.242",
                "llava": "0.512",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.471",
                "llava": "0.500",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.947",
                "llava": "0.670",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.759",
                "llava": "0.500",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00267": {
        "id": "00267",
        "prompt": "Two chairs in the room, both with books on them.",
        "prompt in Chinese": "\u623f\u95f4\u91cc\u6709\u4e24\u628a\u6905\u5b50\uff0c\u4e0a\u9762\u90fd\u653e\u7740\u4e66\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.377",
                "llava": "0.319",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.718",
                "llava": "0.591",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.499",
                "llava": "0.379",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.155",
                "llava": "0.224",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00397": {
        "id": "397",
        "prompt": "A large teddy bear wearing a bow tie next to a small teddy bear wearing a party hat.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.334",
                "llava": "0.586",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.961",
                "llava": "0.828",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.931",
                "llava": "0.816",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.945",
                "llava": "0.710",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00217": {
        "id": "00217",
        "prompt": "A beach with no people, no shells.",
        "prompt in Chinese": "\u4e00\u4e2a\u6ca1\u6709\u4eba\u3001\u4e5f\u6ca1\u6709\u8d1d\u58f3\u7684\u6d77\u6ee9\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.550",
                "llava": "0.604",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.638",
                "llava": "0.637",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.815",
                "llava": "0.698",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.747",
                "llava": "0.587",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00254": {
        "id": "00254",
        "prompt": "In a modern laboratory, all the computer screens are turned on.",
        "prompt in Chinese": "\u5728\u4e00\u4e2a\u73b0\u4ee3\u5b9e\u9a8c\u5ba4\u91cc\uff0c\u6240\u6709\u7684\u7535\u8111\u5c4f\u5e55\u90fd\u5f00\u7740\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.133",
                "llava": "0.302",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.840",
                "llava": "0.765",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.919",
                "llava": "0.812",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.912",
                "llava": "0.701",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00015": {
        "id": "00015",
        "prompt": "A book with glowing runes floating beside a mystic crystal.",
        "prompt in Chinese": "\u4e00\u672c\u95ea\u8000\u7740\u7b26\u6587\u7684\u4e66\u6f02\u6d6e\u5728\u795e\u79d8\u6c34\u6676\u65c1\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.565",
                "llava": "0.568",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.612",
                "llava": "0.421",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.820",
                "llava": "0.653",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.421",
                "llava": "0.558",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00418": {
        "id": "418",
        "prompt": "Every child in the classroom has a smile on their face.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.684",
                "llava": "0.450",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.465",
                "llava": "0.486",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.622",
                "llava": "0.589",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.314",
                "llava": "0.344",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00399": {
        "id": "399",
        "prompt": "A leather-bound journal atop an oak desk, beside a stack of vintage paperbacks.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.527",
                "llava": "0.548",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.609",
                "llava": "0.628",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.864",
                "llava": "0.755",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.818",
                "llava": "0.680",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            }
        }
    },
    "00153": {
        "id": "00153",
        "prompt": "Four disappointed customers and two content sellers.",
        "prompt in Chinese": "\u56db\u4e2a\u5931\u671b\u7684\u987e\u5ba2\u548c\u4e24\u4e2a\u6ee1\u610f\u7684\u5356\u5bb6\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.234",
                "llava": "0.202",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.336",
                "llava": "0.278",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.317",
                "llava": "0.246",
                "human": "1.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.196",
                "llava": "0.151",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00270": {
        "id": "00270",
        "prompt": "A spotted dog, a cat and a bird on a table.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.183",
                "llava": "0.315",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.952",
                "llava": "0.695",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.913",
                "llava": "0.754",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.153",
                "llava": "0.233",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00513": {
        "id": "513",
        "prompt": "One lantern glowing softly next to five pebbles.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.895",
                "llava": "0.671",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.820",
                "llava": "0.605",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.338",
                "llava": "0.519",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.258",
                "llava": "0.315",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00193": {
        "id": "00193",
        "prompt": "A colorful skirt has an uncolorful hem.",
        "prompt in Chinese": "\u4e00\u6761\u6709\u7740\u4e00\u4e2a\u7d20\u8272\u7684\u4e0b\u6446\u7684\u5f69\u8272\u7684\u88d9\u5b50\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.647",
                "llava": "0.695",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.873",
                "llava": "0.659",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.832",
                "llava": "0.717",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.553",
                "llava": "0.657",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00242": {
        "id": "00242",
        "prompt": "A magical flower is taller than the house next to it.",
        "prompt in Chinese": "\u4e00\u6735\u795e\u5947\u7684\u82b1\uff0c\u6bd4\u65c1\u8fb9\u7684\u623f\u5b50\u8fd8\u9ad8\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.522",
                "llava": "0.472",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.434",
                "llava": "0.387",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.835",
                "llava": "0.741",
                "human": "1.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.287",
                "llava": "0.301",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00285": {
        "id": "00285",
        "prompt": "A woman in a long-sleeved dress with a ring.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.522",
                "llava": "0.362",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.602",
                "llava": "0.740",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.739",
                "llava": "0.619",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.761",
                "llava": "0.728",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00031": {
        "id": "00031",
        "prompt": "A man kneads dough on a table.",
        "prompt in Chinese": "\u4e00\u4e2a\u7537\u4eba\u5728\u684c\u4e0a\u63c9\u9762\u56e2\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.909",
                "llava": "0.811",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.946",
                "llava": "0.856",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.666",
                "llava": "0.789",
                "human": "4.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.936",
                "llava": "0.827",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            }
        }
    },
    "00437": {
        "id": "437",
        "prompt": "A shoe with no laces, standing alone.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.498",
                "llava": "0.461",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.720",
                "llava": "0.556",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.480",
                "llava": "0.353",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.570",
                "llava": "0.725",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00409": {
        "id": "409",
        "prompt": "A rooftop garden with a row of planters, each filled with herbs and flowers.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.692",
                "llava": "0.777",
                "human": "4.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.966",
                "llava": "0.895",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.951",
                "llava": "0.864",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.967",
                "llava": "0.867",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00343": {
        "id": "343",
        "prompt": "An astronaut planting a flag on a distant planet.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.834",
                "llava": "0.560",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.605",
                "llava": "0.722",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.575",
                "llava": "0.463",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.371",
                "llava": "0.469",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00169": {
        "id": "00169",
        "prompt": "The girl with glasses is drawing, and the girl without glasses is singing.",
        "prompt in Chinese": "\u6234\u773c\u955c\u7684\u5973\u5b69\u5728\u753b\u753b\uff0c\u4e0d\u6234\u773c\u955c\u7684\u5973\u5b69\u5728\u5531\u6b4c\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.609",
                "llava": "0.460",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.148",
                "llava": "0.170",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.408",
                "llava": "0.349",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.160",
                "llava": "0.181",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00271": {
        "id": "00271",
        "prompt": "A dog, a cat and a chicken on a table.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.661",
                "llava": "0.465",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.972",
                "llava": "0.687",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.167",
                "llava": "0.381",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.119",
                "llava": "0.222",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00309": {
        "id": "309",
        "prompt": "A farmer in overalls tending to a field of corn.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.436",
                "llava": "0.683",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.975",
                "llava": "0.794",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.900",
                "llava": "0.831",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.970",
                "llava": "0.809",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00422": {
        "id": "422",
        "prompt": "On the farm, each animal is settling down for the night.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.441",
                "llava": "0.552",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.262",
                "llava": "0.157",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.673",
                "llava": "0.600",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.284",
                "llava": "0.200",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00263": {
        "id": "00263",
        "prompt": "In an enchanted forest, every tree is joyfully dancing.",
        "prompt in Chinese": "\u9b54\u6cd5\u68ee\u6797\u91cc\uff0c\u6bcf\u68f5\u6811\u90fd\u5728\u6b22\u5feb\u5730\u8df3\u821e\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.363",
                "llava": "0.358",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.245",
                "llava": "0.221",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.475",
                "llava": "0.430",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.207",
                "llava": "0.134",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00387": {
        "id": "387",
        "prompt": "A tall cactus in a terracotta pot next to a short succulent in a ceramic bowl.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.842",
                "llava": "0.717",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.760",
                "llava": "0.742",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.822",
                "llava": "0.754",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.658",
                "llava": "0.724",
                "human": "5.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00364": {
        "id": "364",
        "prompt": "On the bookshelf, the picture frame on the left, containing a black and white photograph, appears older than the colorful painting on the right.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.605",
                "llava": "0.556",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.723",
                "llava": "0.696",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.593",
                "llava": "0.641",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.769",
                "llava": "0.658",
                "human": "1.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00017": {
        "id": "00017",
        "prompt": "A mermaid singing softly near a coral throne undersea.",
        "prompt in Chinese": "\u4e00\u4f4d\u7f8e\u4eba\u9c7c\u5728\u6d77\u5e95\u7684\u73ca\u745a\u5b9d\u5ea7\u65c1\u8f7b\u58f0\u6b4c\u5531\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.642",
                "llava": "0.690",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.803",
                "llava": "0.732",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.751",
                "llava": "0.656",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.715",
                "llava": "0.695",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00279": {
        "id": "00279",
        "prompt": "A young woman in a red long-sleeved dress.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.969",
                "llava": "0.900",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.934",
                "llava": "0.884",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.797",
                "llava": "0.807",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.790",
                "llava": "0.761",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00489": {
        "id": "489",
        "prompt": "A bridge with no one crossing.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.917",
                "llava": "0.748",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.832",
                "llava": "0.771",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.889",
                "llava": "0.729",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.393",
                "llava": "0.646",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00058": {
        "id": "00058",
        "prompt": "A quaint bookshop.",
        "prompt in Chinese": "\u4e00\u5bb6\u53e4\u96c5\u7684\u4e66\u5e97\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.832",
                "llava": "0.845",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.939",
                "llava": "0.920",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.946",
                "llava": "0.874",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.788",
                "llava": "0.729",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00241": {
        "id": "00241",
        "prompt": "A gigantic dog that is taller than the tree next to it.",
        "prompt in Chinese": "\u4e00\u53ea\u5de8\u5927\u7684\u72d7\uff0c\u6bd4\u65c1\u8fb9\u7684\u6811\u8fd8\u8981\u9ad8\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.246",
                "llava": "0.192",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.214",
                "llava": "0.245",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.200",
                "llava": "0.233",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.404",
                "llava": "0.262",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00087": {
        "id": "00087",
        "prompt": "A hammock strung between two palm trees on a beach.",
        "prompt in Chinese": "\u4e00\u5f20\u540a\u5e8a\u7cfb\u5728\u6c99\u6ee9\u4e0a\u4e24\u68f5\u68d5\u6988\u6811\u4e4b\u95f4\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.828",
                "llava": "0.813",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.877",
                "llava": "0.867",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.920",
                "llava": "0.859",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.949",
                "llava": "0.907",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00139": {
        "id": "00139",
        "prompt": "Two cats playing with a single ball.",
        "prompt in Chinese": "\u4e24\u53ea\u732b\u5728\u73a9\u4e00\u4e2a\u7403\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.816",
                "llava": "0.523",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.308",
                "llava": "0.362",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.370",
                "llava": "0.490",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.399",
                "llava": "0.393",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00434": {
        "id": "434",
        "prompt": "A sky with stars, but no moon in sight.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.682",
                "llava": "0.588",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.678",
                "llava": "0.628",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.774",
                "llava": "0.651",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.518",
                "llava": "0.661",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "4"
            }
        }
    },
    "00389": {
        "id": "389",
        "prompt": "A blue bicycle leaning against a red brick wall, with a green bicycle parked beside it.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.480",
                "llava": "0.378",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.393",
                "llava": "0.361",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.428",
                "llava": "0.362",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.154",
                "llava": "0.232",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00469": {
        "id": "469",
        "prompt": "A table set for dinner with plates, but no forks.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.326",
                "llava": "0.324",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.170",
                "llava": "0.213",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.226",
                "llava": "0.273",
                "human": "1.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.477",
                "llava": "0.268",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00495": {
        "id": "495",
        "prompt": "In a crowded room, there are more people standing than sitting.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.631",
                "llava": "0.713",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.756",
                "llava": "0.771",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.855",
                "llava": "0.800",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.848",
                "llava": "0.687",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00300": {
        "id": "300",
        "prompt": "The chairs in the bedroom are all white.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.974",
                "llava": "0.858",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.066",
                "llava": "0.302",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.972",
                "llava": "0.888",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.972",
                "llava": "0.824",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00159": {
        "id": "00159",
        "prompt": "One person talks on the phone animatedly while the other sits sadly.",
        "prompt in Chinese": "\u4e00\u4e2a\u4eba\u5174\u81f4\u52c3\u52c3\u5730\u8bb2\u7535\u8bdd\uff0c\u53e6\u4e00\u4e2a\u4eba\u6101\u7709\u82e6\u8138\u5730\u5750\u7740\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.498",
                "llava": "0.542",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.370",
                "llava": "0.399",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.460",
                "llava": "0.480",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.701",
                "llava": "0.497",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00238": {
        "id": "00238",
        "prompt": "An ancient library hidden beneath the earth, 'Secrets of the Ages' inscribed on the archway, books floating around as if by magic.",
        "prompt in Chinese": "\u4e00\u4e2a\u9690\u85cf\u5728\u5730\u4e0b\u7684\u53e4\u8001\u56fe\u4e66\u9986\uff0c'Secrets of the Ages'\u523b\u5728\u62f1\u95e8\u4e0a\uff0c\u4e66\u7c4d\u5982\u88ab\u65bd\u4e86\u9b54\u6cd5\u4e00\u6837\u6f02\u6d6e\u5728\u5468\u56f4\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.486",
                "llava": "0.472",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.359",
                "llava": "0.428",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.771",
                "llava": "0.719",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.496",
                "llava": "0.387",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00436": {
        "id": "436",
        "prompt": "A birdcage with no door, yet no bird inside.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.812",
                "llava": "0.511",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.202",
                "llava": "0.455",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.217",
                "llava": "0.393",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.766",
                "llava": "0.533",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            }
        }
    },
    "00355": {
        "id": "355",
        "prompt": "A balloon drifts gently up into the blue sky, with excited children watching from the ground.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.242",
                "llava": "0.586",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.763",
                "llava": "0.570",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.889",
                "llava": "0.627",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.428",
                "llava": "0.437",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00189": {
        "id": "00189",
        "prompt": "A bird with no feathers on its head, perched alone.",
        "prompt in Chinese": "\u4e00\u53ea\u5934\u4e0a\u6ca1\u6709\u7fbd\u6bdb\u7684\u9e1f\uff0c\u5b64\u72ec\u5730\u6816\u606f\u7740\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.400",
                "llava": "0.560",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.542",
                "llava": "0.610",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.639",
                "llava": "0.453",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.710",
                "llava": "0.570",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00354": {
        "id": "354",
        "prompt": "Tea steams in a cup, next to a closed diary with a pen resting on its cover.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.188",
                "llava": "0.256",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.677",
                "llava": "0.658",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.455",
                "llava": "0.537",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.758",
                "llava": "0.531",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00190": {
        "id": "00190",
        "prompt": "A car, not red, without its front wheels, parked.",
        "prompt in Chinese": "\u4e00\u8f86\u8f66\uff0c\u4e0d\u662f\u7ea2\u8272\u7684\uff0c\u6ca1\u6709\u524d\u8f6e\uff0c\u505c\u5728\u90a3\u91cc\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.875",
                "llava": "0.685",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.161",
                "llava": "0.233",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.546",
                "llava": "0.513",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.125",
                "llava": "0.189",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00130": {
        "id": "00130",
        "prompt": "In one bedroom the pillows were plump and the blankets neatly folded.",
        "prompt in Chinese": "\u4e00\u95f4\u5367\u5ba4\u91cc\uff0c\u6795\u5934\u84ec\u677e\uff0c\u88ab\u5b50\u53e0\u5f97\u6574\u6574\u9f50\u9f50\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.488",
                "llava": "0.518",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.804",
                "llava": "0.692",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.607",
                "llava": "0.604",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.420",
                "llava": "0.422",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00076": {
        "id": "00076",
        "prompt": "A golden retriever sitting to the left of a blue picket fence.",
        "prompt in Chinese": "\u4e00\u53ea\u91d1\u6bdb\u72ac\u5750\u5728\u84dd\u8272\u6805\u680f\u7684\u5de6\u8fb9\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.752",
                "llava": "0.744",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.765",
                "llava": "0.716",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.864",
                "llava": "0.793",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.719",
                "llava": "0.769",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00337": {
        "id": "337",
        "prompt": "A vampire lurking in the shadows of an old castle.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.104",
                "llava": "0.121",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.668",
                "llava": "0.526",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.710",
                "llava": "0.726",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.194",
                "llava": "0.228",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00175": {
        "id": "00175",
        "prompt": "A happy woman is on the right of a sad woman.",
        "prompt in Chinese": "\u4e00\u4f4d\u5feb\u4e50\u7684\u5973\u58eb\u5728\u4e00\u4f4d\u60b2\u4f24\u7684\u5973\u58eb\u7684\u53f3\u8fb9\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.160",
                "llava": "0.321",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.751",
                "llava": "0.610",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.664",
                "llava": "0.657",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.579",
                "llava": "0.495",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00359": {
        "id": "359",
        "prompt": "Two birds are chasing each other in the air, the one flying higher has a long tail and the other bird has a short tail.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.677",
                "llava": "0.675",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.765",
                "llava": "0.636",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.134",
                "llava": "0.150",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.114",
                "llava": "0.161",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00185": {
        "id": "00185",
        "prompt": "A runner in blue shoes speeds past another in red shoes.",
        "prompt in Chinese": "\u4e00\u4f4d\u7a7f\u7740\u84dd\u8272\u978b\u5b50\u7684\u8dd1\u6b65\u8005\u4ece\u53e6\u4e00\u4f4d\u7a7f\u7740\u7ea2\u8272\u978b\u5b50\u7684\u8dd1\u6b65\u8005\u8eab\u8fb9\u98de\u9a70\u800c\u8fc7\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.658",
                "llava": "0.476",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.793",
                "llava": "0.678",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.461",
                "llava": "0.460",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.142",
                "llava": "0.373",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00132": {
        "id": "00132",
        "prompt": "In a snowy landscape, a fox dashes across the terrain, while nearby, a dog sits calmly.",
        "prompt in Chinese": "\u5728\u4e00\u7247\u96ea\u666f\u4e2d\uff0c\u4e00\u53ea\u72d0\u72f8\u98de\u5954\u800c\u8fc7\uff0c\u65c1\u8fb9\u4e00\u53ea\u72d7\u5b89\u9759\u5730\u5750\u7740",
        "models": {
            "Floor33": {
                "clip_flant5": "0.198",
                "llava": "0.250",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.304",
                "llava": "0.216",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.696",
                "llava": "0.603",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.275",
                "llava": "0.341",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00005": {
        "id": "00005",
        "prompt": "A crystal tree shimmering under a twilit, starry sky.",
        "prompt in Chinese": "\u4e00\u68f5\u5728\u9ec4\u660f\u661f\u7a7a\u4e0b\u95ea\u70c1\u7684\u6c34\u6676\u6811\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.390",
                "llava": "0.671",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.907",
                "llava": "0.702",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.929",
                "llava": "0.680",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.458",
                "llava": "0.573",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00368": {
        "id": "368",
        "prompt": "In the park, the older tree is taller and has more branches than the younger sapling planted beside it.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.732",
                "llava": "0.624",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.689",
                "llava": "0.663",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.685",
                "llava": "0.671",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.550",
                "llava": "0.647",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00298": {
        "id": "298",
        "prompt": "In the bedroom, there are three chairs with a book on each of them.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.353",
                "llava": "0.340",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.568",
                "llava": "0.464",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.276",
                "llava": "0.266",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.065",
                "llava": "0.148",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00385": {
        "id": "385",
        "prompt": "A red book on a shelf above a blue book in a cozy reading nook.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.202",
                "llava": "0.233",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.298",
                "llava": "0.423",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.287",
                "llava": "0.305",
                "human": "1.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.749",
                "llava": "0.532",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            }
        }
    },
    "00229": {
        "id": "00229",
        "prompt": "A 'No Parking' sign on a busy street.",
        "prompt in Chinese": "\u7e41\u5fd9\u8857\u9053\u4e0a\u7684'No Parking'\u6807\u5fd7\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.984",
                "llava": "0.814",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.984",
                "llava": "0.843",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.985",
                "llava": "0.850",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.223",
                "llava": "0.629",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00073": {
        "id": "00073",
        "prompt": "A playful kitten with a bell collar on the left, batting at a fluttering butterfly on the right.",
        "prompt in Chinese": "\u5de6\u8fb9\u4e00\u53ea\u6234\u7740\u94c3\u94db\u9879\u5708\u7684\u987d\u76ae\u5c0f\u732b\uff0c\u6b63\u5728\u7528\u722a\u5b50\u62cd\u6253\u53f3\u8fb9\u98de\u821e\u7684\u8774\u8776\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.081",
                "llava": "0.168",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.810",
                "llava": "0.594",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.227",
                "llava": "0.281",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.246",
                "llava": "0.281",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00372": {
        "id": "372",
        "prompt": "A cyclist wearing glasses speeds down the hill with ease, another one without glasses climbs up slowly and steadily.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.472",
                "llava": "0.336",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.394",
                "llava": "0.312",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.329",
                "llava": "0.433",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.238",
                "llava": "0.312",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00476": {
        "id": "476",
        "prompt": "A musician with a guitar, but no audience to listen.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.565",
                "llava": "0.652",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.816",
                "llava": "0.718",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.544",
                "llava": "0.612",
                "human": "4.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.710",
                "llava": "0.616",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00261": {
        "id": "00261",
        "prompt": "On the grass, all the children are lying down, laughing joyfully.",
        "prompt in Chinese": "\u5728\u8349\u5730\u4e0a\uff0c\u6240\u6709\u7684\u5b69\u5b50\u90fd\u8eba\u7740\uff0c\u6b22\u4e50\u5730\u7b11\u7740\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.332",
                "llava": "0.612",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.947",
                "llava": "0.777",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.893",
                "llava": "0.775",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.419",
                "llava": "0.393",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00320": {
        "id": "320",
        "prompt": "A mechanic working under the hood of a classic car.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.319",
                "llava": "0.566",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.948",
                "llava": "0.864",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.954",
                "llava": "0.843",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.607",
                "llava": "0.522",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00404": {
        "id": "404",
        "prompt": "A plush velvet armchair in the corner of a library, with a sleek leather sofa along the opposite wall.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.720",
                "llava": "0.623",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.242",
                "llava": "0.393",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.590",
                "llava": "0.625",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.645",
                "llava": "0.526",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00011": {
        "id": "00011",
        "prompt": "A pair of winged boots resting on a cloud in the sky.",
        "prompt in Chinese": "\u4e00\u53cc\u6709\u7740\u7fc5\u8180\u7684\u9774\u5b50\u505c\u5728\u5929\u7a7a\u4e2d\u7684\u4e91\u6735\u4e0a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.688",
                "llava": "0.678",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.511",
                "llava": "0.478",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.955",
                "llava": "0.785",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.294",
                "llava": "0.478",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00273": {
        "id": "00273",
        "prompt": "A young man with a blue bat and a green ball.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.226",
                "llava": "0.252",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.979",
                "llava": "0.811",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.224",
                "llava": "0.275",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.179",
                "llava": "0.242",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00098": {
        "id": "00098",
        "prompt": "A vintage car cruising down a coastal road at sunset.",
        "prompt in Chinese": "\u5915\u9633\u897f\u4e0b\uff0c\u4e00\u8f86\u8001\u7237\u8f66\u5728\u6cbf\u6d77\u516c\u8def\u4e0a\u884c\u9a76\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.826",
                "llava": "0.647",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.759",
                "llava": "0.759",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.559",
                "llava": "0.731",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.556",
                "llava": "0.545",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00486": {
        "id": "486",
        "prompt": "A kitchen with every cupboard bare.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.377",
                "llava": "0.276",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.384",
                "llava": "0.215",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.706",
                "llava": "0.758",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.079",
                "llava": "0.285",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "3"
            }
        }
    },
    "00299": {
        "id": "299",
        "prompt": "there are four chairs in the bedroom.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.358",
                "llava": "0.496",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.882",
                "llava": "0.677",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.122",
                "llava": "0.118",
                "human": "1.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.104",
                "llava": "0.166",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00028": {
        "id": "00028",
        "prompt": "A dancer twirls in a spotlight.",
        "prompt in Chinese": "\u4e00\u4e2a\u821e\u8005\u5728\u805a\u5149\u706f\u4e0b\u65cb\u8f6c\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.820",
                "llava": "0.792",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.926",
                "llava": "0.836",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.912",
                "llava": "0.802",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.082",
                "llava": "0.303",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00420": {
        "id": "420",
        "prompt": "Every tree in the forest is covered in snow, creating a serene winter landscape.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.615",
                "llava": "0.623",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.733",
                "llava": "0.664",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.734",
                "llava": "0.717",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.558",
                "llava": "0.630",
                "human": "4.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00036": {
        "id": "00036",
        "prompt": "A boy spots a colorful bird.",
        "prompt in Chinese": "\u4e00\u4f4d\u7537\u5b69\u53d1\u73b0\u4e86\u4e00\u53ea\u4e94\u5f69\u7f24\u7eb7\u7684\u9e1f\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.068",
                "llava": "0.409",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.948",
                "llava": "0.791",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.920",
                "llava": "0.816",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.572",
                "llava": "0.487",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00128": {
        "id": "00128",
        "prompt": "A hat is perched on the table and a coat is draped on the chair.",
        "prompt in Chinese": "\u4e00\u9876\u5e3d\u5b50\u653e\u5728\u684c\u5b50\u4e0a\uff0c\u4e00\u4ef6\u5916\u5957\u642d\u5728\u6905\u5b50\u4e0a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.508",
                "llava": "0.543",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.408",
                "llava": "0.486",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.776",
                "llava": "0.568",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.381",
                "llava": "0.488",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00239": {
        "id": "00239",
        "prompt": "In a mysterious swamp, the flowers are taller than the trees.",
        "prompt in Chinese": "\u5728\u795e\u79d8\u7684\u6cbc\u6cfd\u91cc\uff0c\u82b1\u6735\u6bd4\u6811\u6728\u8fd8\u8981\u9ad8\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.664",
                "llava": "0.732",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.538",
                "llava": "0.537",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.458",
                "llava": "0.543",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.543",
                "llava": "0.403",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00378": {
        "id": "378",
        "prompt": "A short sunflower stands tall and faces the sun, while another tall one bends towards the ground.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.592",
                "llava": "0.555",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.529",
                "llava": "0.504",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.533",
                "llava": "0.572",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.594",
                "llava": "0.629",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00080": {
        "id": "00080",
        "prompt": "A blue mailbox standing to the left of a winding garden path.",
        "prompt in Chinese": "\u4e00\u5c01\u84dd\u8272\u90ae\u7b52\u7acb\u5728\u873f\u8712\u82b1\u56ed\u5c0f\u5f84\u7684\u5de6\u4fa7\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.858",
                "llava": "0.773",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.320",
                "llava": "0.746",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.937",
                "llava": "0.815",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.932",
                "llava": "0.730",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00164": {
        "id": "00164",
        "prompt": "A circular mirror is above a rectangular one.",
        "prompt in Chinese": "\u4e00\u9762\u5706\u5f62\u955c\u5b50\u5728\u4e00\u9762\u957f\u65b9\u5f62\u955c\u5b50\u7684\u4e0a\u65b9\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.752",
                "llava": "0.594",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.392",
                "llava": "0.434",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.450",
                "llava": "0.554",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.298",
                "llava": "0.334",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00001": {
        "id": "00001",
        "prompt": "A baker pulling freshly baked bread out of an oven in a bakery.",
        "prompt in Chinese": "\u4e00\u4f4d\u9762\u5305\u5e08\u6b63\u4ece\u9762\u5305\u5e97\u7684\u70e4\u7bb1\u4e2d\u53d6\u51fa\u521a\u70e4\u597d\u7684\u9762\u5305\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.671",
                "llava": "0.734",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.880",
                "llava": "0.868",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.799",
                "llava": "0.767",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.517",
                "llava": "0.523",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00227": {
        "id": "00227",
        "prompt": "An elegant wedding venue, a 'Just Married' banner draped across the back of a vintage car.",
        "prompt in Chinese": "\u4e00\u4e2a\u4f18\u96c5\u7684\u5a5a\u793c\u573a\u5730\uff0c\u4e00\u8f86\u590d\u53e4\u6c7d\u8f66\u7684\u540e\u90e8\u60ac\u6302\u7740'Just Married'\u7684\u6a2a\u5e45\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.330",
                "llava": "0.620",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.866",
                "llava": "0.729",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.811",
                "llava": "0.795",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.816",
                "llava": "0.704",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00038": {
        "id": "00038",
        "prompt": "A bird nocks an arrow.",
        "prompt in Chinese": "\u4e00\u53ea\u9e1f\u6b63\u5728\u51c6\u5907\u5c04\u7bad\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.094",
                "llava": "0.179",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.155",
                "llava": "0.153",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.371",
                "llava": "0.279",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.247",
                "llava": "0.283",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00430": {
        "id": "430",
        "prompt": "Every lamp in the street is lit, except for one that remains dark.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.594",
                "llava": "0.470",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.507",
                "llava": "0.572",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.412",
                "llava": "0.389",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.326",
                "llava": "0.440",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00465": {
        "id": "465",
        "prompt": "A kitchen with every appliance except a microwave.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.508",
                "llava": "0.459",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.423",
                "llava": "0.487",
                "human": "5.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.509",
                "llava": "0.515",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.444",
                "llava": "0.456",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00192": {
        "id": "00192",
        "prompt": "A pair of glasses, but no lenses.",
        "prompt in Chinese": "\u4e00\u526f\u773c\u955c\u6846\uff0c\u4f46\u6ca1\u6709\u955c\u7247\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.655",
                "llava": "0.677",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.805",
                "llava": "0.624",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.321",
                "llava": "0.681",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.912",
                "llava": "0.749",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            }
        }
    },
    "00377": {
        "id": "377",
        "prompt": "One sports car zooms around the corner with speed, while another standard car navigates the turn slowly and carefully.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.715",
                "llava": "0.536",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.271",
                "llava": "0.407",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.605",
                "llava": "0.564",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.400",
                "llava": "0.522",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00148": {
        "id": "00148",
        "prompt": "One content rabbit and six tired turtles.",
        "prompt in Chinese": "\u4e00\u4e2a\u6ee1\u8db3\u7684\u5154\u5b50\u548c\u516d\u53ea\u75b2\u60eb\u7684\u4e4c\u9f9f\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.489",
                "llava": "0.385",
                "human": "1.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.099",
                "llava": "0.172",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.240",
                "llava": "0.209",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.089",
                "llava": "0.189",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00013": {
        "id": "00013",
        "prompt": "An ice castle standing proudly in the midst of a blizzard.",
        "prompt in Chinese": "\u4e00\u5ea7\u51b0\u96d5\u57ce\u5821\u5728\u66b4\u98ce\u96ea\u4e2d\u50b2\u7136\u5c79\u7acb\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.688",
                "llava": "0.636",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.666",
                "llava": "0.708",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.744",
                "llava": "0.681",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.452",
                "llava": "0.568",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00296": {
        "id": "296",
        "prompt": "A cute dog without a collar.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.086",
                "llava": "0.150",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.118",
                "llava": "0.168",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.573",
                "llava": "0.507",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.370",
                "llava": "0.367",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00174": {
        "id": "00174",
        "prompt": "There are three men, the one in the center is jumping, the others are standing.",
        "prompt in Chinese": "\u6709\u4e09\u4e2a\u4eba\uff0c\u4e2d\u95f4\u7684\u4eba\u5728\u8df3\uff0c\u5176\u4ed6\u4eba\u7ad9\u7740\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.083",
                "llava": "0.238",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.882",
                "llava": "0.467",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.099",
                "llava": "0.326",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.396",
                "llava": "0.476",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            }
        }
    },
    "00431": {
        "id": "431",
        "prompt": "In a pack of wolves, each one howls at the moon, but one remains silent.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.271",
                "llava": "0.396",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.376",
                "llava": "0.399",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.469",
                "llava": "0.380",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.384",
                "llava": "0.372",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00216": {
        "id": "00216",
        "prompt": "A cat sleeps peacefully in a dog's bed, while the dog has no choice but to nap on the floor.",
        "prompt in Chinese": "\u4e00\u53ea\u732b\u5728\u72d7\u7684\u5e8a\u4e0a\u5b89\u9759\u5730\u7761\u89c9\uff0c\u800c\u72d7\u53ea\u80fd\u5728\u5730\u677f\u4e0a\u6253\u76f9\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.382",
                "llava": "0.333",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.380",
                "llava": "0.393",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.301",
                "llava": "0.315",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.388",
                "llava": "0.459",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            }
        }
    },
    "00037": {
        "id": "00037",
        "prompt": "A sailor hoists a sail.",
        "prompt in Chinese": "\u4e00\u4f4d\u6c34\u624b\u5347\u8d77\u5e06\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.673",
                "llava": "0.703",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.741",
                "llava": "0.767",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.377",
                "llava": "0.512",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.924",
                "llava": "0.784",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            }
        }
    },
    "00260": {
        "id": "00260",
        "prompt": "A bustling kitchen where every chef is preparing a dish.",
        "prompt in Chinese": "\u4e00\u4e2a\u7e41\u5fd9\u7684\u53a8\u623f\uff0c\u6bcf\u4f4d\u53a8\u5e08\u90fd\u5728\u51c6\u5907\u4e00\u9053\u83dc\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.661",
                "llava": "0.708",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.651",
                "llava": "0.661",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.714",
                "llava": "0.773",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.557",
                "llava": "0.494",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00451": {
        "id": "451",
        "prompt": "A forest where no animals can be seen.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.067",
                "llava": "0.193",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.688",
                "llava": "0.608",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.726",
                "llava": "0.651",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.414",
                "llava": "0.506",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00487": {
        "id": "487",
        "prompt": "A mirror with no reflection.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.167",
                "llava": "0.276",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.360",
                "llava": "0.274",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.315",
                "llava": "0.359",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.476",
                "llava": "0.476",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            }
        }
    },
    "00488": {
        "id": "488",
        "prompt": "A calendar with no dates marked.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.302",
                "llava": "0.473",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.491",
                "llava": "0.350",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.561",
                "llava": "0.371",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.331",
                "llava": "0.559",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "4"
            }
        }
    },
    "00450": {
        "id": "450",
        "prompt": "A beach without any footprints in the sand.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.581",
                "llava": "0.549",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.639",
                "llava": "0.592",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.497",
                "llava": "0.549",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.119",
                "llava": "0.214",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00438": {
        "id": "438",
        "prompt": "A garden with no paths, only wildflowers.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.830",
                "llava": "0.773",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.851",
                "llava": "0.791",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.297",
                "llava": "0.533",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.820",
                "llava": "0.769",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00234": {
        "id": "00234",
        "prompt": "'Art Center' is spray-painted on the wall of the City Gallery.",
        "prompt in Chinese": "Art Center'\u88ab\u55b7\u6d82\u5728\u57ce\u5e02\u753b\u5eca\u7684\u5899\u4e0a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.519",
                "llava": "0.554",
                "human": "1.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.204",
                "llava": "0.319",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.700",
                "llava": "0.614",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.651",
                "llava": "0.657",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00405": {
        "id": "405",
        "prompt": "In the cafe, there's a steaming cup of coffee and a freshly baked croissant on every table.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.490",
                "llava": "0.608",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.614",
                "llava": "0.637",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.679",
                "llava": "0.609",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.634",
                "llava": "0.637",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00163": {
        "id": "00163",
        "prompt": "A lone green banana stands out among a cluster of red bananas.",
        "prompt in Chinese": "\u5728\u4e00\u7c07\u7ea2\u8272\u7684\u9999\u8549\u4e2d\uff0c\u4e00\u679d\u7eff\u8272\u7684\u9999\u8549\u683c\u5916\u663e\u773c\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.204",
                "llava": "0.390",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.853",
                "llava": "0.701",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.614",
                "llava": "0.575",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.508",
                "llava": "0.597",
                "human": "1.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00482": {
        "id": "482",
        "prompt": "A snowy hill with children sledding, but no snowman in sight.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.691",
                "llava": "0.708",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.735",
                "llava": "0.713",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.771",
                "llava": "0.740",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.625",
                "llava": "0.747",
                "human": "4.67",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00182": {
        "id": "00182",
        "prompt": "A single snowflake falls gracefully among others swirling chaotically in the wind.",
        "prompt in Chinese": "\u4e00\u7247\u96ea\u82b1\u4f18\u96c5\u5730\u98d8\u843d\u5728\u968f\u98ce\u4e71\u98de\u7684\u96ea\u82b1\u4e2d\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.493",
                "llava": "0.528",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.464",
                "llava": "0.460",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.303",
                "llava": "0.408",
                "human": "4.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.454",
                "llava": "0.409",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00019": {
        "id": "00019",
        "prompt": "A unicorn grazing peacefully in a radiant, rainbow-lit glade.",
        "prompt in Chinese": "\u4e00\u53ea\u72ec\u89d2\u517d\u5728\u4e00\u4e2a\u5149\u8292\u56db\u5c04\u3001\u5f69\u8679\u7167\u8000\u7684\u6797\u95f4\u7a7a\u5730\u4e0a\u5e73\u9759\u5730\u5403\u8349\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.648",
                "llava": "0.637",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.711",
                "llava": "0.630",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.540",
                "llava": "0.663",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.446",
                "llava": "0.519",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00208": {
        "id": "00208",
        "prompt": "A garden with flowers, but no bees to be seen.",
        "prompt in Chinese": "\u4e00\u4e2a\u6709\u82b1\u7684\u82b1\u56ed\uff0c\u4f46\u770b\u4e0d\u5230\u871c\u8702\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.598",
                "llava": "0.625",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.536",
                "llava": "0.569",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.347",
                "llava": "0.459",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.625",
                "llava": "0.557",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00194": {
        "id": "00194",
        "prompt": "A plate with no food, only a fork and a knife.",
        "prompt in Chinese": "\u4e00\u4e2a\u76d8\u5b50\u4e0a\u6ca1\u6709\u98df\u7269\uff0c\u53ea\u6709\u4e00\u628a\u53c9\u5b50\u548c\u4e00\u628a\u5200\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.782",
                "llava": "0.561",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.117",
                "llava": "0.207",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.619",
                "llava": "0.770",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.164",
                "llava": "0.251",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00371": {
        "id": "371",
        "prompt": "Two birds soar high above the clouds, while another glides low over the water.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.245",
                "llava": "0.320",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.489",
                "llava": "0.432",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.406",
                "llava": "0.465",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.194",
                "llava": "0.224",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00516": {
        "id": "516",
        "prompt": "Five buttons sewn onto a piece of fabric with two needles.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.172",
                "llava": "0.322",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.265",
                "llava": "0.380",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.340",
                "llava": "0.232",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.551",
                "llava": "0.507",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00184": {
        "id": "00184",
        "prompt": "Among a group of pastel-colored balloons, one stands out in vibrant red.",
        "prompt in Chinese": "\u5728\u4e00\u7fa4\u67d4\u548c\u8272\u5f69\u7684\u6c14\u7403\u4e2d\uff0c\u4e00\u4e2a\u7ea2\u8272\u7684\u6c14\u7403\u683c\u5916\u663e\u773c\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.862",
                "llava": "0.754",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.562",
                "llava": "0.650",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.149",
                "llava": "0.411",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.885",
                "llava": "0.763",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00325": {
        "id": "325",
        "prompt": "A photographer capturing a butterfly on a wildflower.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.426",
                "llava": "0.541",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.818",
                "llava": "0.659",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.114",
                "llava": "0.308",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.333",
                "llava": "0.306",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00398": {
        "id": "398",
        "prompt": "An orange tabby cat lounges on a sunny windowsill, with a grey tabby stretching on the floor below.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.285",
                "llava": "0.280",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.310",
                "llava": "0.331",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.482",
                "llava": "0.483",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.240",
                "llava": "0.347",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00205": {
        "id": "00205",
        "prompt": "In a race between a tortoise and a hare, the tortoise takes a nap, but the hare does not.",
        "prompt in Chinese": "\u5728\u4e4c\u9f9f\u548c\u5154\u5b50\u7684\u6bd4\u8d5b\u4e2d\uff0c\u4e4c\u9f9f\u5728\u6253\u76f9\uff0c\u4f46\u5154\u5b50\u6ca1\u6709\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.249",
                "llava": "0.402",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.431",
                "llava": "0.407",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.297",
                "llava": "0.400",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.461",
                "llava": "0.354",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00025": {
        "id": "00025",
        "prompt": "A cat pounces on a rolling ball.",
        "prompt in Chinese": "\u4e00\u53ea\u732b\u6251\u5411\u4e00\u4e2a\u6eda\u52a8\u7684\u7403\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.930",
                "llava": "0.752",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.478",
                "llava": "0.497",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.491",
                "llava": "0.590",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.426",
                "llava": "0.617",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "3"
            }
        }
    },
    "00274": {
        "id": "00274",
        "prompt": "parent pointing at a child.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.847",
                "llava": "0.844",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.814",
                "llava": "0.819",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.889",
                "llava": "0.793",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.341",
                "llava": "0.569",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00403": {
        "id": "403",
        "prompt": "A steaming cup of coffee on a bookshelf, above a row of antique tea cups.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.460",
                "llava": "0.476",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.705",
                "llava": "0.505",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.267",
                "llava": "0.381",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.271",
                "llava": "0.475",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00435": {
        "id": "435",
        "prompt": "A street with no people, only lights.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.291",
                "llava": "0.596",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.881",
                "llava": "0.803",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.750",
                "llava": "0.792",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.846",
                "llava": "0.713",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00471": {
        "id": "471",
        "prompt": "A road with cars, but no traffic lights.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.563",
                "llava": "0.565",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.113",
                "llava": "0.176",
                "human": "4.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.752",
                "llava": "0.678",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.443",
                "llava": "0.594",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00043": {
        "id": "00043",
        "prompt": "A yellow taxi waiting outside a modern glass building.",
        "prompt in Chinese": "\u4e00\u8f86\u9ec4\u8272\u51fa\u79df\u8f66\u505c\u5728\u73b0\u4ee3\u73bb\u7483\u5efa\u7b51\u5916\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.848",
                "llava": "0.861",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.957",
                "llava": "0.857",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.827",
                "llava": "0.802",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.369",
                "llava": "0.628",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00131": {
        "id": "00131",
        "prompt": "A guitar rests against a chair and a drum set stands nearby.",
        "prompt in Chinese": "\u4e00\u628a\u5409\u4ed6\u9760\u5728\u6905\u5b50\u4e0a\uff0c\u4e00\u5957\u67b6\u5b50\u9f13\u7acb\u5728\u65c1\u8fb9\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.612",
                "llava": "0.593",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.387",
                "llava": "0.498",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.390",
                "llava": "0.516",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.820",
                "llava": "0.750",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            }
        }
    },
    "00213": {
        "id": "00213",
        "prompt": "A vase with water, but no flowers to nourish.",
        "prompt in Chinese": "\u82b1\u74f6\u6709\u6c34\uff0c\u5374\u65e0\u82b1\u6ecb\u6da6\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.372",
                "llava": "0.665",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.666",
                "llava": "0.685",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.879",
                "llava": "0.795",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.840",
                "llava": "0.763",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00307": {
        "id": "307",
        "prompt": "A pilot in aviator sunglasses stepping into a small plane.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.258",
                "llava": "0.636",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.869",
                "llava": "0.686",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.357",
                "llava": "0.493",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.658",
                "llava": "0.479",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00314": {
        "id": "314",
        "prompt": "A sculptor chiseling a piece of marble.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.717",
                "llava": "0.843",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.709",
                "llava": "0.822",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.785",
                "llava": "0.786",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.824",
                "llava": "0.737",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00382": {
        "id": "382",
        "prompt": "A puppy on the right chases its tail in circles, while another one on the left lies quietly, watching.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.346",
                "llava": "0.441",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.383",
                "llava": "0.425",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.328",
                "llava": "0.458",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.365",
                "llava": "0.254",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00329": {
        "id": "329",
        "prompt": "A bride throwing her bouquet in a garden wedding.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.307",
                "llava": "0.503",
                "human": "4.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.609",
                "llava": "0.591",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.922",
                "llava": "0.749",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.496",
                "llava": "0.651",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00466": {
        "id": "466",
        "prompt": "A classroom full of students, but no teacher in sight.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.797",
                "llava": "0.719",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.683",
                "llava": "0.743",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.554",
                "llava": "0.717",
                "human": "5.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.600",
                "llava": "0.620",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00061": {
        "id": "00061",
        "prompt": "A pilot with aviator sunglasses.",
        "prompt in Chinese": "\u4e00\u4f4d\u6234\u7740\u98de\u884c\u5458\u592a\u9633\u955c\u7684\u98de\u884c\u5458\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.403",
                "llava": "0.645",
                "human": "3.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.763",
                "llava": "0.827",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.945",
                "llava": "0.785",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.799",
                "llava": "0.818",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            }
        }
    },
    "00243": {
        "id": "00243",
        "prompt": "A green pumpkin is smiling happily, a red pumpkin is sitting sadly.",
        "prompt in Chinese": "\u4e00\u4e2a\u7eff\u8272\u7684\u5357\u74dc\u6b63\u5f00\u5fc3\u5730\u5fae\u7b11\uff0c\u4e00\u4e2a\u7ea2\u8272\u7684\u5357\u74dc\u6b63\u60b2\u4f24\u5730\u5750\u7740\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.269",
                "llava": "0.272",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.609",
                "llava": "0.457",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.413",
                "llava": "0.555",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.362",
                "llava": "0.536",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00215": {
        "id": "00215",
        "prompt": "A mountain with no snow, under a bright sky.",
        "prompt in Chinese": "\u660e\u4eae\u7684\u5929\u7a7a\u4e0b\uff0c\u4e00\u5ea7\u6ca1\u6709\u96ea\u7684\u5c71\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.352",
                "llava": "0.427",
                "human": "4.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.461",
                "llava": "0.340",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.223",
                "llava": "0.468",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.199",
                "llava": "0.170",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00292": {
        "id": "292",
        "prompt": "A young man is holding a blue bat and a green ball.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.114",
                "llava": "0.209",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.416",
                "llava": "0.484",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.230",
                "llava": "0.294",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.252",
                "llava": "0.198",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00365": {
        "id": "365",
        "prompt": "On the road, two cars drive parallel: the faster one is a sleek sports model, while the slower one is a large, family SUV.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.507",
                "llava": "0.555",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.824",
                "llava": "0.682",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.144",
                "llava": "0.262",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.270",
                "llava": "0.419",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00090": {
        "id": "00090",
        "prompt": "A red bicycle against a blue wall.",
        "prompt in Chinese": "\u4e00\u8f86\u7ea2\u8272\u81ea\u884c\u8f66\u9760\u5728\u84dd\u8272\u5899\u58c1\u4e0a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.743",
                "llava": "0.805",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.508",
                "llava": "0.524",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.458",
                "llava": "0.698",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.933",
                "llava": "0.799",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00262": {
        "id": "00262",
        "prompt": "A classroom where every student's desk is covered with creative projects and experiments.",
        "prompt in Chinese": "\u4e00\u4e2a\u6559\u5ba4\uff0c\u6bcf\u4e2a\u5b66\u751f\u7684\u684c\u5b50\u4e0a\u90fd\u6446\u6ee1\u4e86\u521b\u610f\u9879\u76ee\u548c\u5b9e\u9a8c\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.221",
                "llava": "0.148",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.326",
                "llava": "0.372",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.442",
                "llava": "0.759",
                "human": "1.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.380",
                "llava": "0.276",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00454": {
        "id": "454",
        "prompt": "A classroom with every chair empty.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.747",
                "llava": "0.740",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.658",
                "llava": "0.767",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.672",
                "llava": "0.725",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.602",
                "llava": "0.635",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00342": {
        "id": "342",
        "prompt": "A robot dancing in a futuristic cityscape.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.763",
                "llava": "0.757",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.518",
                "llava": "0.643",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.640",
                "llava": "0.650",
                "human": "4.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.698",
                "llava": "0.757",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00207": {
        "id": "00207",
        "prompt": "A garden where flowers grow out of pots without soil.",
        "prompt in Chinese": "\u4e00\u4e2a\u82b1\u56ed\u91cc\uff0c\u82b1\u6735\u4ece\u6ca1\u6709\u571f\u58e4\u7684\u76c6\u91cc\u751f\u957f\u51fa\u6765\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.433",
                "llava": "0.544",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.426",
                "llava": "0.445",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.451",
                "llava": "0.521",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.531",
                "llava": "0.528",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00178": {
        "id": "00178",
        "prompt": "The larger person wears a yellow hat and the smaller person does not.",
        "prompt in Chinese": "\u8f83\u5927\u7684\u4eba\u6234\u7740\u9ec4\u8272\u7684\u5e3d\u5b50\uff0c\u8f83\u5c0f\u7684\u4eba\u6ca1\u6709\u6234\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.668",
                "llava": "0.647",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.846",
                "llava": "0.699",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.414",
                "llava": "0.570",
                "human": "1.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.292",
                "llava": "0.512",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00020": {
        "id": "00020",
        "prompt": "A magical quill writing tales by itself on an empty scroll.",
        "prompt in Chinese": "\u4e00\u652f\u9b54\u6cd5\u7fbd\u6bdb\u7b14\u81ea\u5df1\u5728\u4e00\u5f20\u7a7a\u767d\u7684\u5377\u8f74\u4e0a\u4e66\u5199\u6545\u4e8b\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.293",
                "llava": "0.413",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.124",
                "llava": "0.185",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.304",
                "llava": "0.285",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.377",
                "llava": "0.432",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            }
        }
    },
    "00419": {
        "id": "419",
        "prompt": "Basking in the sunshine, all the cats are peacefully sleeping.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.077",
                "llava": "0.136",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.391",
                "llava": "0.331",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.468",
                "llava": "0.587",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.444",
                "llava": "0.545",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00083": {
        "id": "00083",
        "prompt": "A cat sitting to the left of a bookshelf.",
        "prompt in Chinese": "\u4e00\u53ea\u732b\u5750\u5728\u4e66\u67b6\u7684\u5de6\u4fa7\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.747",
                "llava": "0.846",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.901",
                "llava": "0.846",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.668",
                "llava": "0.800",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.646",
                "llava": "0.695",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00172": {
        "id": "00172",
        "prompt": "The brown dog chases the black dog around the tree.",
        "prompt in Chinese": "\u68d5\u8272\u7684\u72d7\u7ed5\u7740\u6811\u8ffd\u7740\u9ed1\u8272\u7684\u72d7\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.432",
                "llava": "0.556",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.718",
                "llava": "0.593",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.148",
                "llava": "0.286",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.167",
                "llava": "0.265",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00310": {
        "id": "310",
        "prompt": "A child blowing bubbles in a field of daisies.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.925",
                "llava": "0.754",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.522",
                "llava": "0.631",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.234",
                "llava": "0.425",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.342",
                "llava": "0.473",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00452": {
        "id": "452",
        "prompt": "A sky without a single cloud.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.071",
                "llava": "0.191",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.062",
                "llava": "0.165",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.241",
                "llava": "0.308",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.483",
                "llava": "0.458",
                "human": "1.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            }
        }
    },
    "00196": {
        "id": "00196",
        "prompt": "A person without a hat pays a person with a hat.",
        "prompt in Chinese": "\u6ca1\u6709\u6234\u5e3d\u5b50\u7684\u4eba\u4ed8\u94b1\u7ed9\u6234\u5e3d\u5b50\u7684\u4eba\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.155",
                "llava": "0.296",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.076",
                "llava": "0.173",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.301",
                "llava": "0.272",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.170",
                "llava": "0.238",
                "human": "1.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00280": {
        "id": "00280",
        "prompt": "A cat chasing a dog.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.117",
                "llava": "0.298",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.130",
                "llava": "0.201",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.809",
                "llava": "0.639",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.210",
                "llava": "0.418",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00453": {
        "id": "453",
        "prompt": "A garden with no flowers blooming.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.047",
                "llava": "0.279",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.037",
                "llava": "0.160",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.762",
                "llava": "0.678",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.447",
                "llava": "0.466",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00502": {
        "id": "502",
        "prompt": "A bakery display with more chocolate pastries than fruit-filled ones.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.621",
                "llava": "0.829",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.057",
                "llava": "0.068",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.800",
                "llava": "0.889",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.854",
                "llava": "0.839",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            }
        }
    },
    "00390": {
        "id": "390",
        "prompt": "A brown oak tree with lush leaves next to a birch tree with peeling bark in a forest.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.289",
                "llava": "0.348",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.313",
                "llava": "0.376",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.231",
                "llava": "0.331",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.156",
                "llava": "0.231",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00396": {
        "id": "396",
        "prompt": "A vintage analog clock hangs on the wall above a modern digital clock that sits on a desk.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.320",
                "llava": "0.383",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.213",
                "llava": "0.355",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.261",
                "llava": "0.506",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.477",
                "llava": "0.327",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00012": {
        "id": "00012",
        "prompt": "A talking mirror whispering secrets in a dim chamber.",
        "prompt in Chinese": "\u4e00\u9762\u4f1a\u8bf4\u8bdd\u7684\u955c\u5b50\u5728\u660f\u6697\u7684\u623f\u95f4\u91cc\u4f4e\u8bed\u79d8\u5bc6\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.239",
                "llava": "0.368",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.222",
                "llava": "0.364",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.476",
                "llava": "0.536",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.087",
                "llava": "0.079",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00256": {
        "id": "00256",
        "prompt": "Inside a library where each book spine displays a unique, intricate pattern.",
        "prompt in Chinese": "\u5728\u4e00\u4e2a\u56fe\u4e66\u9986\u5185\uff0c\u6bcf\u672c\u4e66\u7684\u4e66\u810a\u90fd\u5c55\u793a\u7740\u72ec\u7279\u3001\u7cbe\u7ec6\u7684\u56fe\u6848\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.542",
                "llava": "0.523",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.449",
                "llava": "0.576",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.471",
                "llava": "0.522",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.600",
                "llava": "0.770",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            }
        }
    },
    "00101": {
        "id": "00101",
        "prompt": "An astronaut floating gracefully in the vastness of space outside a spacecraft.",
        "prompt in Chinese": "\u4e00\u4f4d\u5b87\u822a\u5458\u5728\u5b87\u5b99\u98de\u8239\u5916\u7684\u6d69\u701a\u592a\u7a7a\u4e2d\u4f18\u96c5\u5730\u6f02\u6d6e\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.288",
                "llava": "0.377",
                "human": "4.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.602",
                "llava": "0.629",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.442",
                "llava": "0.619",
                "human": "4.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.576",
                "llava": "0.619",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00236": {
        "id": "00236",
        "prompt": "A sign in park says 'Bike Lane.'",
        "prompt in Chinese": "\u516c\u56ed\u91cc\u7684\u4e00\u5757\u724c\u5b50\u4e0a\u5199\u7740'Bike Lane'\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.250",
                "llava": "0.207",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.646",
                "llava": "0.656",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.671",
                "llava": "0.705",
                "human": "1.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.330",
                "llava": "0.672",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00413": {
        "id": "413",
        "prompt": "Near every parked pickup truck, there's a horse standing by.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.084",
                "llava": "0.085",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.226",
                "llava": "0.438",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.625",
                "llava": "0.608",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.288",
                "llava": "0.439",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00018": {
        "id": "00018",
        "prompt": "A goblin trading shiny trinkets in a hidden, mystical market.",
        "prompt in Chinese": "\u4e00\u53ea\u5996\u7cbe\u5728\u4e00\u4e2a\u9690\u85cf\u7684\u3001\u795e\u79d8\u7684\u5e02\u573a\u91cc\u4ea4\u6613\u95ea\u4eae\u7684\u5c0f\u9970\u54c1\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.543",
                "llava": "0.636",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.489",
                "llava": "0.641",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.606",
                "llava": "0.612",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.368",
                "llava": "0.465",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00259": {
        "id": "00259",
        "prompt": "A garden where every flower is in full bloom, showcasing a rainbow of colors.",
        "prompt in Chinese": "\u4e00\u4e2a\u82b1\u56ed\u91cc\uff0c\u6bcf\u6735\u82b1\u90fd\u76db\u5f00\u7740\uff0c\u5c55\u73b0\u51fa\u4e00\u7247\u5f69\u8679\u822c\u7684\u8272\u5f69\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.490",
                "llava": "0.661",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.731",
                "llava": "0.751",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.689",
                "llava": "0.750",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.654",
                "llava": "0.750",
                "human": "4.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00211": {
        "id": "00211",
        "prompt": "The tallest tree in the forest has no leaves, while the smallest one is lush and green.",
        "prompt in Chinese": "\u68ee\u6797\u4e2d\u6700\u9ad8\u7684\u6811\u6ca1\u6709\u53f6\u5b50\uff0c\u800c\u6700\u5c0f\u7684\u6811\u5374\u90c1\u90c1\u8471\u8471\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.418",
                "llava": "0.694",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.651",
                "llava": "0.560",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.459",
                "llava": "0.545",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.408",
                "llava": "0.492",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00014": {
        "id": "00014",
        "prompt": "A potion bubbling brightly inside a cauldron in a shadowy nook.",
        "prompt in Chinese": "\u5728\u9634\u6697\u89d2\u843d\u91cc\uff0c\u5927\u9505\u91cc\u836f\u6c34\u5192\u7740\u660e\u4eae\u7684\u6c14\u6ce1\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.196",
                "llava": "0.486",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.528",
                "llava": "0.567",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.790",
                "llava": "0.717",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.280",
                "llava": "0.381",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00463": {
        "id": "463",
        "prompt": "A bustling city street with cars, but no bicycles.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.107",
                "llava": "0.160",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.189",
                "llava": "0.351",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.165",
                "llava": "0.263",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.402",
                "llava": "0.456",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00415": {
        "id": "415",
        "prompt": "At a birthday party, all the balloons are red.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.887",
                "llava": "0.807",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.846",
                "llava": "0.797",
                "human": "4.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.364",
                "llava": "0.684",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.089",
                "llava": "0.265",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00401": {
        "id": "401",
        "prompt": "A chocolate cupcake with vanilla frosting on a plate, beside a vanilla cupcake with chocolate frosting.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.375",
                "llava": "0.594",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.703",
                "llava": "0.652",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.349",
                "llava": "0.486",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.473",
                "llava": "0.539",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00199": {
        "id": "00199",
        "prompt": "A cat without visible ears is riding.",
        "prompt in Chinese": "\u4e00\u53ea\u770b\u4e0d\u89c1\u8033\u6735\u7684\u732b\u5728\u9a91\u884c\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.057",
                "llava": "0.166",
                "human": "1.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.046",
                "llava": "0.124",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.059",
                "llava": "0.196",
                "human": "1.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.054",
                "llava": "0.109",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00373": {
        "id": "373",
        "prompt": "A tree laden with ripe oranges stands in front of a tree with green, unripe fruit.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.623",
                "llava": "0.642",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.606",
                "llava": "0.739",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.717",
                "llava": "0.665",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.427",
                "llava": "0.708",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00108": {
        "id": "00108",
        "prompt": "A table setting with fewer forks than bowls.",
        "prompt in Chinese": "\u9910\u684c\u4e0a\uff0c\u53c9\u5b50\u7684\u6570\u91cf\u5c11\u4e8e\u7897\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.488",
                "llava": "0.557",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.493",
                "llava": "0.639",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.519",
                "llava": "0.626",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.470",
                "llava": "0.545",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00416": {
        "id": "416",
        "prompt": "A group of children are playing in the garden and all the children are not wearing shoes.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.420",
                "llava": "0.483",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.358",
                "llava": "0.662",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.898",
                "llava": "0.771",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.532",
                "llava": "0.701",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00421": {
        "id": "421",
        "prompt": "In the park, every bench is occupied by people enjoying their books.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.049",
                "llava": "0.133",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.292",
                "llava": "0.460",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.186",
                "llava": "0.325",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.080",
                "llava": "0.113",
                "human": "1.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00447": {
        "id": "447",
        "prompt": "A coat with no buttons, hanging loosely.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.670",
                "llava": "0.609",
                "human": "1.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.251",
                "llava": "0.431",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.447",
                "llava": "0.577",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.399",
                "llava": "0.576",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00007": {
        "id": "00007",
        "prompt": "A fairy dancing lightly atop a blooming, moonlit flower.",
        "prompt in Chinese": "\u4e00\u4f4d\u4ed9\u5b50\u8f7b\u5de7\u5730\u5728\u6708\u5149\u4e0b\u7efd\u653e\u7684\u82b1\u6735\u4e0a\u8d77\u821e\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.720",
                "llava": "0.750",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.721",
                "llava": "0.734",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.430",
                "llava": "0.638",
                "human": "3.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.463",
                "llava": "0.643",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00029": {
        "id": "00029",
        "prompt": "A boy leaps over a hurdle.",
        "prompt in Chinese": "\u4e00\u4e2a\u7537\u5b69\u8dc3\u8fc7\u969c\u788d\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.813",
                "llava": "0.840",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.947",
                "llava": "0.899",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.392",
                "llava": "0.763",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.434",
                "llava": "0.531",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00103": {
        "id": "00103",
        "prompt": "A pencil holder with more pens than pencils.",
        "prompt in Chinese": "\u4e00\u4e2a\u7b14\u7b52\u91cc\u4e2d\u7684\u94a2\u7b14\u6bd4\u94c5\u7b14\u591a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.343",
                "llava": "0.495",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.305",
                "llava": "0.431",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.314",
                "llava": "0.453",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.519",
                "llava": "0.553",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00212": {
        "id": "00212",
        "prompt": "A car moves forward but a bicycle doesn't.",
        "prompt in Chinese": "\u4e00\u8f86\u8f66\u5728\u5411\u524d\u884c\u9a76\uff0c\u4e00\u8f86\u81ea\u884c\u8f66\u6ca1\u6709\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.409",
                "llava": "0.480",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.099",
                "llava": "0.344",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.708",
                "llava": "0.593",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.183",
                "llava": "0.452",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00449": {
        "id": "449",
        "prompt": "A library with no books on the shelves.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.181",
                "llava": "0.314",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.115",
                "llava": "0.217",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.231",
                "llava": "0.316",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.081",
                "llava": "0.245",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00264": {
        "id": "00264",
        "prompt": "Little fairies are flying in the sky, each with pink butterfly wings.",
        "prompt in Chinese": "\u5c0f\u7cbe\u7075\u5728\u5929\u7a7a\u4e2d\u98de\u7fd4\uff0c\u6bcf\u4e2a\u5c0f\u7cbe\u7075\u90fd\u957f\u7740\u7c89\u7ea2\u8272\u7684\u8774\u8776\u7fc5\u8180\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.239",
                "llava": "0.564",
                "human": "1.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.638",
                "llava": "0.626",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.959",
                "llava": "0.716",
                "human": "4.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.234",
                "llava": "0.659",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "3"
            }
        }
    },
    "00287": {
        "id": "00287",
        "prompt": "A dog, a cat and a bird on a chair.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.120",
                "llava": "0.156",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.139",
                "llava": "0.248",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.141",
                "llava": "0.362",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.067",
                "llava": "0.203",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00369": {
        "id": "369",
        "prompt": "A red book lies open with pages fluttering in the wind, another blue one remains closed and still.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.510",
                "llava": "0.514",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.482",
                "llava": "0.590",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.240",
                "llava": "0.527",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.301",
                "llava": "0.410",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00275": {
        "id": "00275",
        "prompt": "A child pointing at parent.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.259",
                "llava": "0.496",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.491",
                "llava": "0.477",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.350",
                "llava": "0.553",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.428",
                "llava": "0.511",
                "human": "1.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            }
        }
    },
    "00105": {
        "id": "00105",
        "prompt": "A couple where the taller one hugs the shorter from behind.",
        "prompt in Chinese": "\u4e00\u5bf9\u60c5\u4fa3\uff0c\u4e2a\u5b50\u9ad8\u4ece\u540e\u9762\u62b1\u4f4f\u4e2a\u5b50\u77ee\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.491",
                "llava": "0.732",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.711",
                "llava": "0.839",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.697",
                "llava": "0.795",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.716",
                "llava": "0.763",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "4"
            }
        }
    },
    "00485": {
        "id": "485",
        "prompt": "A zoo with no animals in the enclosures.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.771",
                "llava": "0.594",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.083",
                "llava": "0.532",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.768",
                "llava": "0.710",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.080",
                "llava": "0.418",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00424": {
        "id": "424",
        "prompt": "In a room, all the chairs are occupied except one.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.312",
                "llava": "0.561",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.206",
                "llava": "0.335",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.304",
                "llava": "0.454",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.243",
                "llava": "0.303",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00491": {
        "id": "491",
        "prompt": "A fountain with no water flowing.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.131",
                "llava": "0.206",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.093",
                "llava": "0.192",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.239",
                "llava": "0.489",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.062",
                "llava": "0.228",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00334": {
        "id": "334",
        "prompt": "A florist arranging a bouquet of colorful flowers.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.240",
                "llava": "0.736",
                "human": "5.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.909",
                "llava": "0.851",
                "human": "5.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.534",
                "llava": "0.768",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.815",
                "llava": "0.756",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00210": {
        "id": "00210",
        "prompt": "A car drives down the road without wheels, floating above the ground.",
        "prompt in Chinese": "\u4e00\u8f86\u6c7d\u8f66\u5728\u8def\u4e0a\u884c\u9a76\uff0c\u6ca1\u6709\u8f6e\u5b50\uff0c\u6f02\u6d6e\u5728\u5730\u9762\u4e0a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.082",
                "llava": "0.287",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.114",
                "llava": "0.177",
                "human": "1.00",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.560",
                "llava": "0.736",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.106",
                "llava": "0.276",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            }
        }
    },
    "00112": {
        "id": "00112",
        "prompt": "A forest landscape with more birds in the sky than trees on the ground.",
        "prompt in Chinese": "\u4e00\u4e2a\u68ee\u6797\u666f\u89c2\uff0c\u5929\u7a7a\u4e2d\u7684\u9e1f\u6bd4\u5730\u9762\u4e0a\u7684\u6811\u591a\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.570",
                "llava": "0.647",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.466",
                "llava": "0.689",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.590",
                "llava": "0.750",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.108",
                "llava": "0.265",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00100": {
        "id": "00100",
        "prompt": "A librarian shelving books in a quiet, expansive library.",
        "prompt in Chinese": "\u4e00\u4f4d\u56fe\u4e66\u7ba1\u7406\u5458\u5728\u5b81\u9759\u3001\u5bbd\u655e\u7684\u56fe\u4e66\u9986\u91cc\u6574\u7406\u4e66\u7c4d\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.370",
                "llava": "0.529",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.268",
                "llava": "0.563",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.384",
                "llava": "0.502",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.363",
                "llava": "0.423",
                "human": "3.33",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            }
        }
    },
    "00327": {
        "id": "327",
        "prompt": "A magician pulling a rabbit out of a hat.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.348",
                "llava": "0.529",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.236",
                "llava": "0.440",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.390",
                "llava": "0.509",
                "human": "2.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.216",
                "llava": "0.379",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00455": {
        "id": "455",
        "prompt": "A clock with no hands to tell the time.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.228",
                "llava": "0.515",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.193",
                "llava": "0.474",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.367",
                "llava": "0.481",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.522",
                "llava": "0.507",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "1"
            }
        }
    },
    "00497": {
        "id": "497",
        "prompt": "A snowy landscape with deeper snow than the height of the nearby fence.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.576",
                "llava": "0.746",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.616",
                "llava": "0.803",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.665",
                "llava": "0.791",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.539",
                "llava": "0.736",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00410": {
        "id": "410",
        "prompt": "A tree shadow on every car in the lot.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.550",
                "llava": "0.554",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.481",
                "llava": "0.574",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.083",
                "llava": "0.419",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.322",
                "llava": "0.584",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "4"
            }
        }
    },
    "00120": {
        "id": "00120",
        "prompt": "A fish glides through the air, while a bird plunges underwater.",
        "prompt in Chinese": "\u9c7c\u513f\u5728\u7a7a\u4e2d\u6ed1\u7fd4\uff0c\u9e1f\u513f\u5728\u6c34\u4e0b\u98de\u7fd4\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.211",
                "llava": "0.409",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.108",
                "llava": "0.423",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.362",
                "llava": "0.427",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.152",
                "llava": "0.277",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00346": {
        "id": "346",
        "prompt": "Sunglasses rest atop a magazine, and a beach towel is spread out on the sand.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.137",
                "llava": "0.247",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.310",
                "llava": "0.460",
                "human": "1.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.071",
                "llava": "0.231",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.229",
                "llava": "0.532",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "3"
            }
        }
    },
    "00460": {
        "id": "460",
        "prompt": "A field without a single blade of grass.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.081",
                "llava": "0.357",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.195",
                "llava": "0.236",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.235",
                "llava": "0.442",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.314",
                "llava": "0.536",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            }
        }
    },
    "00444": {
        "id": "444",
        "prompt": "A bed with no pillows, only a folded blanket.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.132",
                "llava": "0.191",
                "human": "4.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "1"
            },
            "Gen2": {
                "clip_flant5": "0.523",
                "llava": "0.781",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.320",
                "llava": "0.631",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.385",
                "llava": "0.526",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    },
    "00032": {
        "id": "00032",
        "prompt": "A person types on an old typewriter.",
        "prompt in Chinese": "\u4e00\u4e2a\u4eba\u5728\u65e7\u5f0f\u6253\u5b57\u673a\u4e0a\u6253\u5b57\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.742",
                "llava": "0.823",
                "human": "2.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.179",
                "llava": "0.552",
                "human": "1.00",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.978",
                "llava": "0.905",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.120",
                "llava": "0.516",
                "human": "1.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00459": {
        "id": "459",
        "prompt": "A mountain with no snow on its peak.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.150",
                "llava": "0.392",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.236",
                "llava": "0.450",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.195",
                "llava": "0.453",
                "human": "3.00",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.685",
                "llava": "0.751",
                "human": "3.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00188": {
        "id": "00188",
        "prompt": "A bookshelf with no books, only a single red vase.",
        "prompt in Chinese": "\u4e66\u67b6\u4e0a\u6ca1\u6709\u4e66\uff0c\u53ea\u6709\u4e00\u4e2a\u7ea2\u8272\u82b1\u74f6\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.199",
                "llava": "0.546",
                "human": "2.33",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.084",
                "llava": "0.153",
                "human": "2.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.146",
                "llava": "0.301",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.156",
                "llava": "0.395",
                "human": "2.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            }
        }
    },
    "00255": {
        "id": "00255",
        "prompt": "A landscape where every tree is in full bloom, with petals covering the entirety of the ground.",
        "prompt in Chinese": "\u4e00\u4e2a\u98ce\u666f\u753b\uff0c\u6bcf\u68f5\u6811\u90fd\u76db\u5f00\u7740\u82b1\uff0c\u82b1\u74e3\u8986\u76d6\u4e86\u6574\u4e2a\u5730\u9762\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.295",
                "llava": "0.549",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.565",
                "llava": "0.716",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.451",
                "llava": "0.685",
                "human": "3.67",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.329",
                "llava": "0.508",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00445": {
        "id": "445",
        "prompt": "A bike with no pedals.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.244",
                "llava": "0.464",
                "human": "5.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.139",
                "llava": "0.500",
                "human": "2.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.518",
                "llava": "0.608",
                "human": "4.67",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.487",
                "llava": "0.639",
                "human": "5.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00457": {
        "id": "457",
        "prompt": "A road with no signs or markings.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.221",
                "llava": "0.453",
                "human": "2.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.160",
                "llava": "0.340",
                "human": "2.67",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.231",
                "llava": "0.606",
                "human": "3.00",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.258",
                "llava": "0.329",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "4",
                "human_rank": "1"
            }
        }
    },
    "00104": {
        "id": "00104",
        "prompt": "A building with more doors than windows.",
        "prompt in Chinese": "\u4e00\u4e2a\u95e8\u6bd4\u7a97\u6237\u591a\u7684\u5efa\u7b51\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.620",
                "llava": "0.638",
                "human": "1.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.160",
                "llava": "0.518",
                "human": "1.67",
                "clip_flant5_rank": "3",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Pika_v1": {
                "clip_flant5": "0.104",
                "llava": "0.390",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.240",
                "llava": "0.443",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00440": {
        "id": "440",
        "prompt": "A boat with no sails, adrift on calm waters.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.479",
                "llava": "0.624",
                "human": "4.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.470",
                "llava": "0.657",
                "human": "4.33",
                "clip_flant5_rank": "2",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.386",
                "llava": "0.569",
                "human": "2.00",
                "clip_flant5_rank": "3",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.181",
                "llava": "0.601",
                "human": "4.33",
                "clip_flant5_rank": "4",
                "llava_rank": "3",
                "human_rank": "1"
            }
        }
    },
    "00349": {
        "id": "349",
        "prompt": "Bookends hold a row of novels in place: one end features a sculpture of a cat, the other a dog.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.566",
                "llava": "0.622",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.298",
                "llava": "0.527",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.143",
                "llava": "0.599",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Modelscope": {
                "clip_flant5": "0.319",
                "llava": "0.521",
                "human": "1.67",
                "clip_flant5_rank": "2",
                "llava_rank": "4",
                "human_rank": "3"
            }
        }
    },
    "00328": {
        "id": "328",
        "prompt": "A detective examining clues with a magnifying glass.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.386",
                "llava": "0.597",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "3",
                "human_rank": "2"
            },
            "Gen2": {
                "clip_flant5": "0.622",
                "llava": "0.619",
                "human": "3.00",
                "clip_flant5_rank": "1",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Pika_v1": {
                "clip_flant5": "0.135",
                "llava": "0.467",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "3"
            },
            "Modelscope": {
                "clip_flant5": "0.307",
                "llava": "0.753",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "1",
                "human_rank": "1"
            }
        }
    },
    "00251": {
        "id": "00251",
        "prompt": "Three floating islands above one  waterfall in a valley.",
        "prompt in Chinese": "\u4e00\u4e2a\u5c71\u8c37\u4e2d\u7684\u7011\u5e03\u4e0a\u65b9\u6709\u4e09\u4e2a\u6f02\u6d6e\u7684\u5c9b\u5c7f\u3002",
        "models": {
            "Floor33": {
                "clip_flant5": "0.164",
                "llava": "0.599",
                "human": "2.00",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "3"
            },
            "Gen2": {
                "clip_flant5": "0.158",
                "llava": "0.448",
                "human": "2.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.159",
                "llava": "0.484",
                "human": "2.00",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.052",
                "llava": "0.147",
                "human": "1.33",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            }
        }
    },
    "00308": {
        "id": "308",
        "prompt": "A young librarian is shelving books in a cozy library corner.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.130",
                "llava": "0.470",
                "human": "3.00",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.323",
                "llava": "0.618",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "2"
            },
            "Pika_v1": {
                "clip_flant5": "0.211",
                "llava": "0.521",
                "human": "3.67",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "1"
            },
            "Modelscope": {
                "clip_flant5": "0.296",
                "llava": "0.574",
                "human": "3.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "3"
            }
        }
    },
    "00297": {
        "id": "297",
        "prompt": "A cat is not black and its tail isn't visible.",
        "models": {
            "Floor33": {
                "clip_flant5": "0.275",
                "llava": "0.546",
                "human": "1.33",
                "clip_flant5_rank": "2",
                "llava_rank": "2",
                "human_rank": "4"
            },
            "Gen2": {
                "clip_flant5": "0.494",
                "llava": "0.710",
                "human": "3.67",
                "clip_flant5_rank": "1",
                "llava_rank": "1",
                "human_rank": "1"
            },
            "Pika_v1": {
                "clip_flant5": "0.084",
                "llava": "0.516",
                "human": "1.67",
                "clip_flant5_rank": "4",
                "llava_rank": "4",
                "human_rank": "2"
            },
            "Modelscope": {
                "clip_flant5": "0.134",
                "llava": "0.536",
                "human": "1.33",
                "clip_flant5_rank": "3",
                "llava_rank": "3",
                "human_rank": "3"
            }
        }
    }
}